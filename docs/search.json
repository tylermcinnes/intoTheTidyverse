[
  {
    "objectID": "intoTheTidyverse.html",
    "href": "intoTheTidyverse.html",
    "title": "Into the tidyverse",
    "section": "",
    "text": "The tidyverse is a collection of R tools, which we call packages, that were designed to be easy to use, easy to read, and work well together. To understand the tidyverse, we need to know some of the history of R.\n\n\nR was created in 1993 by Ross Ihaka and Robert Gentleman at the University of Auckland. It was designed as a tool to teach statistics, and it’s been widely adopted by the field of biology. Over time many people have developed R packages - packages can be approximately thought as like apps on a phone - which focus on specific analyses. For example, if you want to identify differentially expressed genes using RNA-seq data, there is an R package that can perform various statistical tests and normalisation steps. Actually, there are lots of packages that will do this, and the hard part is choosing which one to use. All of these packages are developed by the community, which is great, and initially they were all written in what we call “base R”.\nBase R, and all the R packages that were developed using it, are a bit like the English language: for those who grew up with it, it’s beautifully flexible, expressive, and intuitive. For anyone learning English as an adult…why on earth is there a “g” in night? (Or a “k” in knight, for that matter). Base R packages, like the English language, are a mix of styles and formats depending on who wrote them.\n\n\n\nThe tidyverse is a series of packages that have been designed from the ground up to work together, using a consistent, logical style. It’s written to be human readable, intuitive, and easy to learn. The tidyverse is highly popular and is well documented. My personal opinion: if I was going to learn R now, I would choose to focus on learning the tidyverse.\nThe tidyverse is also a mindset about how data should be presented and stored. Data is “tidy” if:\n\nEach variable is stored in a column (variables could be Age, Height, Occupation).\nEach observation is stored in a row (here, observations could be individuals).\nTogether, these rows and columns form a table.",
    "crumbs": [
      "Welcome to the tidyverse"
    ]
  },
  {
    "objectID": "intoTheTidyverse.html#what-is-the-tidyverse",
    "href": "intoTheTidyverse.html#what-is-the-tidyverse",
    "title": "Into the tidyverse",
    "section": "",
    "text": "The tidyverse is a collection of R tools, which we call packages, that were designed to be easy to use, easy to read, and work well together. To understand the tidyverse, we need to know some of the history of R.\n\n\nR was created in 1993 by Ross Ihaka and Robert Gentleman at the University of Auckland. It was designed as a tool to teach statistics, and it’s been widely adopted by the field of biology. Over time many people have developed R packages - packages can be approximately thought as like apps on a phone - which focus on specific analyses. For example, if you want to identify differentially expressed genes using RNA-seq data, there is an R package that can perform various statistical tests and normalisation steps. Actually, there are lots of packages that will do this, and the hard part is choosing which one to use. All of these packages are developed by the community, which is great, and initially they were all written in what we call “base R”.\nBase R, and all the R packages that were developed using it, are a bit like the English language: for those who grew up with it, it’s beautifully flexible, expressive, and intuitive. For anyone learning English as an adult…why on earth is there a “g” in night? (Or a “k” in knight, for that matter). Base R packages, like the English language, are a mix of styles and formats depending on who wrote them.\n\n\n\nThe tidyverse is a series of packages that have been designed from the ground up to work together, using a consistent, logical style. It’s written to be human readable, intuitive, and easy to learn. The tidyverse is highly popular and is well documented. My personal opinion: if I was going to learn R now, I would choose to focus on learning the tidyverse.\nThe tidyverse is also a mindset about how data should be presented and stored. Data is “tidy” if:\n\nEach variable is stored in a column (variables could be Age, Height, Occupation).\nEach observation is stored in a row (here, observations could be individuals).\nTogether, these rows and columns form a table.",
    "crumbs": [
      "Welcome to the tidyverse"
    ]
  },
  {
    "objectID": "intoTheTidyverse.html#into-the-tidyverse",
    "href": "intoTheTidyverse.html#into-the-tidyverse",
    "title": "Into the tidyverse",
    "section": "Into the tidyverse",
    "text": "Into the tidyverse\nIn this workshop series we will start out assuming you know nothing about R. We will assume that you are either doing this workshop using the live website*. We will first introduce the two building blocks of R: functions and objects. Simultaneously we will look at visualisations and the concept of exploratory data analysis.\nOnce you know what a function is we will look at how functions work in the tidyverse style - this is where we will introduce you to the “pipe”. The pipe, or “piping” is a way to pass information from one function to another.\nThis workshop places a strong focus on practice and repetition through exercises. You are attempting to learn a language, and you can’t do that without practice. Once you have experience with the basics, we will increase the pace and introduce you to a wider toolbox of functions that can be used to achieve your goals.\nThis workshop series draws from R for Data Science, second edition, which should be considered the primary resource for a person learning to work within the tidyverse. It is strongly recommended reading for anyone interested in R and data science.\n*If you are not working on the website, you will need to do some work on your own to get R and RStudio, as well as certain R packages, installed on your computer. These installations may sound intimidating but they can be completed with some reading on google.",
    "crumbs": [
      "Welcome to the tidyverse"
    ]
  },
  {
    "objectID": "episode_1_functions.html",
    "href": "episode_1_functions.html",
    "title": "Episode 1 - Functions",
    "section": "",
    "text": "R has two building blocks. Objects, which we can think of as files, and Functions, which we can think of as “things that do things”. Do you want to calculate the mean of some numbers? There’s a function for that. Do you want to count the number of times a name has appeared in a list? There’s a function for that. Do you want to identify differentially expressed genes in an RNA-seq experiment? There’s a function for that too, but I will say up front that you’ll need to spend some time getting your data into the right format before that function will work.",
    "crumbs": [
      "Episode 1 - Functions"
    ]
  },
  {
    "objectID": "episode_1_functions.html#format-of-a-function",
    "href": "episode_1_functions.html#format-of-a-function",
    "title": "Episode 1 - Functions",
    "section": "Format of a function",
    "text": "Format of a function\n\n\n\n\n\n\n\n\nFunctions have a name and are always followed by a set of round brackets. Inside the round brackets is the target of the function. Here, we have used the library() function to load a package (you can think of a package as being like an app, which usually contains more functions and sometimes some example data). The package we have loaded is called palmerpenguins, which is a collection of data about penguins. The data is stored as an object called penguins. We can use functions to look at the penguins object:",
    "crumbs": [
      "Episode 1 - Functions"
    ]
  },
  {
    "objectID": "episode_1_functions.html#the-pipe",
    "href": "episode_1_functions.html#the-pipe",
    "title": "Episode 1 - Functions",
    "section": "The pipe",
    "text": "The pipe\nBefore we go any further, let’s look at a slightly better way to use functions, which uses the “pipe”.\n\n\n\n\n\n\n\n\nIn this format we start with the data, and we pipe it to a function.\nThere are a lot of different functions we can use to view our data. Try some of these functions out for yourself, and see if you can figure out what each function is doing. It’s worth typing these manually to develop muscle memory. Functions to try:\n\nhead()\ntail()\nstr()\nsummary()\ndim()\n\nIn the space below, after the |&gt;, delete the ______ and type a function from above, then click the “Run Code” button on blue. If you make a mistake, you can always click “Start Over” to refresh the box.\n\n\n\n\n\n\n\n\nWhat do you notice about the output of each of these functions? What have you learned about the penguin data so far?\n\nHelp!\nWhenever you encounter a function and you don’t know what it’s doing, you can always ask for help. In the box below, try typing ?head(). This will give you a readout of the manual page for the head() function. These can be dense, but the Description can be informative.\n\n\n\n\n\n\n\n\nAfter the Description there is some example code, and below that is a section called Arguments. So far, we’ve only been giving functions the one argument they require (usually, this is a target, like some data). But functions can usually accept additional arguments that modify precisely how the function works. Let’s look at the head function, which normally returns the top six rows of an object. Within the head() function, we can specify the number of rows we want to see with the “n =” argument:\n\n\n\n\n\n\n\n\nThere are two key takeaways here:\n\nWith arguments we can alter and control how a function works. This can be as small as changing the number of rows we see, or it can be as significant as changing a method! (e.g., we can specify whether adjusted p values are calculated with the FDR or Bonferroni method).\nFunctions have default arguments, and we often don’t see them! For example, the head() function uses n = 6 as a default, and unless we check, we wouldn’t know that. When you become more familiar with functions, it’s worth glancing at the function manual to get an idea of what arguments are being used as defaults.\n\n\n\nThe pipe, continued\nWriting functions using the pipe format, where data is specified first and then passed to a function, results in code that is very clear and easy to read. This is truly apparent when we start to do more complex things with our data, specifically when we incorporate more than one function.\nLet’s say I want to remove all the NAs in the bill_length_mm column, then round the values to the nearest whole number, then check that’s worked by viewing the first 6 values. With the pipe, we start with the data and read from left to right:\n\n\n\n\n\n\n\n\nEasy, right! We read from left to right, and we can track what is happening at each step as it’s separated by the pipe.\nWhat would this code look like without the pipe, where we put the target inside the function? In this case, we have to ‘nest’ the functions within one another, and to make sense of it we need to read from the inside out.\n\n\n\n\n\n\n\n\nReadable, when you have plenty of experience in R. You’ll probably see plenty of code like this online - it’s not wrong, and many people (me included) learned to write like this. Hopefully you find the tidyverse style, combined with the pipe, makes reading and writing code a lot easier.",
    "crumbs": [
      "Episode 1 - Functions"
    ]
  },
  {
    "objectID": "episode_1_functions.html#specifying-data-columns",
    "href": "episode_1_functions.html#specifying-data-columns",
    "title": "Episode 1 - Functions",
    "section": "Specifying data columns",
    "text": "Specifying data columns\nNotice in the above code the use of the “$” sign? It’s used to specify the name of a column in a 2D object (like the penguins object). We can use the column names to directly and specifically refer to a column in an object. You’ll see that you can also use values (i.e., you can say “give me column 3”)….but this runs into issues if you end up changing the order or number of columns. Column names and the $ are a clear and unabiguous way of specifying data\nUse the colnames() function (and the pipe, of course) to see the column names of the penguins object:\n\n\n\n\n\n\n\n\nWe can also type penguins and the “$” symbol and RStudio will prompt us with a dropdown menu of column names. We can narrow this down by typing the first few letters of the column name we want. In your own console, type penguins$ and use the dropdown to select a column, and pass that data to the head() function with the pipe. If the output looks like a numerical value, pass that column data to the mean() function to calculate the mean. You’ll probably need to pass the data to na.omit() first!",
    "crumbs": [
      "Episode 1 - Functions"
    ]
  },
  {
    "objectID": "episode_1_functions.html#exploratory-data-analysis",
    "href": "episode_1_functions.html#exploratory-data-analysis",
    "title": "Episode 1 - Functions",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nExploratory data analysis is a broad term for familiarising yourself with your data. You’re attempting to ‘get a feel’ for the data. Is it normally distributed? Are any samples clear outliers? Is there missing data? It can take a lot of forms, and is a real skill. To start with, let’s practice visualising different groups within the data.\nTo decide where to start, let’s first use the summary function to get an overview of the penguins object:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nRemember to start with the penguins object, then use the pipe to pass the data to the summary() function.\npenguins |&gt; summary()\n\n\n\n\nFrom here I can think about what types of plots we can create. Based on this summary I could plot:\n\nCorrelation (scatter plots) for combinations of bill length, bill depth, flipper length, and body mass.\nBoxplots showing any measurement (e.g., bill depth) grouped by sex, island, species, or year.\nCombinations of these plots.\n\n\nRemoving NAs and creating objects\nI can see in the summary output that there are NAs in the dataset. These will possibly cause small issues downstream, so I’ll take the precaution of removing them all here. Note that removing NAs is a reasonably drastic step and isn’t something to do lightly when working with your own data.\n\n\n\n\n\n\n\n\nHere we have used the “&lt;-” to assign the output from na.omit() into a new object. Note that we don’t get any confirmation that this line of code has executed, so it’s worth double-checking this has been successful with the head() function. If you are working in an RStudio environment (i.e., not a website) you will have an R “environment” in the top right of the screen showing all your objects.\n\n\nPlotting bill length with ggplot2\nMost modern R workshops include a section on the Grammer of Graphics, or the ggplot2 function. ggplot2 is a way to create visualisations within the tidyverse. It can seem overwhelming at first, but once you recognise the template that all plots are built on, it will become quick and easy to create a variety of plots with different data types with minimal extra work.\nThe format for the ggplot2 template is as follows:\n\nspecify the data\nmap variables e.g., map a column the x axis\ncreate the plot\n\n\n\n\n\n\n\n\n\nSome things to note about the format:\n\nIndentations are important. We use new lines and tabs to keep the code organised. Generally you’ll want to specify only one thing per line (e.g., data, x axis and y axis get there own lines).\nThe ggplot formula is a slight break away from the use of pipes.\nThere are actually two separate functions here: the ggplot() function, which is used to specify the data and map the variables, and the geom_boxplot() function which is used to create the actual plot. Because we want these two functions to work together, at the very end of the ggplot() function, we have added a “+” symbol. RStudio interprets this to mean “Ok, the ggplot function has finished, but I need to read it in the context of the next function”.\ngeom_boxplot() is the function for making boxplots. To make a bar plot we would use geom_bar(), to make a scatter plot we use geom_point() etc.,. Type geom_ in the console and scroll the dropdown menu to see the different geom types - there are plenty!\n\nUse the code block below, remove the hash symbols then fill in any variable for the x and the y axis. See how the plots change. Can you create any combinations that are non-sensical, or do not work? Rather than copy-pasting, try and type out the full code each time (this will build muscle memory and make remembering the ggplot template easier).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nRemember that data = must be filled in with penData. For x and y, you can choose any column name listed by colnames() above.\n\n\n\n\n\n\nExtending ggplot2\nSo far we have made (or broken!) a couple of basic plots. Let’s extend our ggplot2 template to include some useful information like a title and a way to control the axes labels.\nFirst, fill in the aes() function arguments: map the island variable to the x axis, and the bill_length_mm variable to the y axis:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nAes requires that you fill in both x and y, and assign a variable to each one. The format is “x = island”.\n\n\n\n\nA useful thing we can do is to make data points different colours based on another variable. To do this, we can add more to the mapping function. Remember that mapping involves taking a variable and associating it with a feature on the plot - that can be the x axis, y axis, or it can colour. Below, we will add “colour = island” within the mapping function. This will assign the island variable to colour.\n\n\n\n\n\n\n\n\nWhere this gets really interesting is when we map colour = species (instead of colour = island). Now we are able to plot an additional variable, treating colour as a new axis to differentiate the data:\n\n\n\n\n\n\n\n\nThis new mapping configuration reveals that Adelie penguins are found on all three islands, while Chinstrap and Gentoo are found only on Dream and Biscoe islands respectively. What initially looked like island-specific differences in bill length were actually species-specific differences!\nThis type of discovery is the core concern of exploratory analysis. This information was not easily available to us while the data was in a spreadsheet or table form, but it is immediately apparent when visualised.\n\n\nOther geoms\nLet’s look at another common type of plot: the scatter plot. To create the scatter plot we need to select two continuous variables (e.g., do not use categorical variables such as sex, island, or species). We will replace geom_boxplot with the new geom_point() function, and in the arguments for this function we will add size (the size of the data point) and alpha (how opaque/transparent the point is). You will need to fill in the missing information first.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nThe ggplot function has two arguments:\n\ndata\nmapping\n\n\n\n\n\nWhat do you notice when looking at this plot? (Other than how pleasantly aesthetic the default colours are in ggplot2).\nPerhaps, like me, you have a vague sense that there are two different groups here. This could be because of the distribution of the data points - it looks like there is a cluster of less-well correlated points in the bottom left, and a second, more tightly correlated group in the top right.\nOne clue comes from colouring the points by sex - we see a repeating pattern from bottom left to top right, which starts with a cluster of females, then a cluster of males, then another cluster of females, and another cluster of males. In many bird species the male is on average heavier than the female (although, the opposite is true in many raptor species), so it is strange to see a sub-cluster of females that are heavier than a sub-cluster of males.\n\nExercise\nRecreate the plot above, but this time, change colour = sex to colour = species. Add in a new mapping argument shape = sex so that we can view both sex and species at the same time.\n\n\n\n\n\n\n\n\nWe had the advantage of knowing that species contributes to differences in bill length, thanks to our earlier plot, so we probably would have known to colour our samples by species, but in the future we might not be aware of sub-structures within our data. Learning to spot trends (like a group being heterogenous) is an important skill to train.\nClear your digital workspace so that you cannot see the code used to create the previous plots. Now, run penData |&gt; summary() to see the data you are working with. Working only from memory, make a new scatter plot that maps bill_depth_mm to the x axis and flipper_length_mm to the y axis.\nIf you are unable to perfectly recreate the code from memory - that’s very normal! Get as far as you can and attempt to run the code. Use the hints when you need to, and the final solution is available.\nFinally, note down some general conclusions about the data based on your new visualisation.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nThe first function is ggplot, and it requires two arguments: data, and mapping.\nMapping will involve starting the aes function which holds the x, y, colour, and shape variables.\n\n\n\n\n\n\n\n\n\n\n\nHint 2\n\n\n\n\n\nAfter the ggplot() function is complete, the “+” symbol tells R that there’s another function incoming.\nThe second function defines the type of plot: in this case geom_point(), which is taking arguments for size and alpha.\nBecause we have another function coming after geom_point(), remember to add a “+” at the end of the line!\n\n\n\n\n\n\n\n\n\n\n\nHint 3\n\n\n\n\n\nWe have two functions to add labels and a title:\nlabs(), which adds a label to the x and the y axis (and is followed by a “+” symbol, since it’s not the last function).\nggtitle(), which adds a title. Since this is finally the last function, no + is needed.\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nFully worked solution:\nggplot(data = penData,\n   mapping = aes(x = bill_length_mm,\n   \n                 y = flipper_length_mm,\n                 \n                 colour = species,\n                 \n                 shape = sex)) +\n                 \ngeom_point(size = 2, alpha = 0.6) +\nlabs(x = “Bill depth (mm)”,\n   y = \"Flipper length (mm)\") +\n   \nggtitle(“Bill depth vs flipper length”)",
    "crumbs": [
      "Episode 1 - Functions"
    ]
  },
  {
    "objectID": "episode_1_functions.html#the-completed-figure",
    "href": "episode_1_functions.html#the-completed-figure",
    "title": "Episode 1 - Functions",
    "section": "The completed figure",
    "text": "The completed figure\nHere is the complete figure, to which we have added an additional argument (“scale_colour_viridis(discrete = TRUE)”, plus “library(viridis)”) to change the colour defaults to a more colourblind-friendly palette.\n\n\n\n\n\n\n\n\nYou now have a basic grasp of functions, and appreciate the value of visualising your data.",
    "crumbs": [
      "Episode 1 - Functions"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Into the tidyverse",
    "section": "",
    "text": "Maybe this is your first encounter with R, or maybe you’ve self-taught and stumbled your way through a plot, or maybe you’ve been using base R for ages and you want to pick up some of the tidyverse (that’s where I fit in, by the way). Whatever your situation, this workshop is going to introduce you to the tidyverse, get you started with some exercises, and then set you loose with enough tools to explore things comfortably (and safely) on your own.",
    "crumbs": [
      "Into the tidyverse"
    ]
  }
]