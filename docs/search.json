[
  {
    "objectID": "episode_4_tidytuesday.html",
    "href": "episode_4_tidytuesday.html",
    "title": "Episode 4 Tidy Tuesday",
    "section": "",
    "text": "So far you’ve learned some of the basics of both ggplot and the tidyverse. In this brief episode you will see a real example of the dplyr verbs being used to transform a dataset for visualisation.",
    "crumbs": [
      "Episode 4 - tidytuesday"
    ]
  },
  {
    "objectID": "episode_4_tidytuesday.html#tidytuesday",
    "href": "episode_4_tidytuesday.html#tidytuesday",
    "title": "Episode 4 Tidy Tuesday",
    "section": "tidytuesday",
    "text": "tidytuesday\n“tidytuesday” is a weekly community event aimed at getting people involved in data exploration and visualisation. Each week a dataset is provided and a brief is given out. The brief includes an overview of the dataset and recommends a focus (e.g., search for relationships within certain categories, how could this dataset be tidied, what visualisations work best with this type of data). Community members are encouraged to share their code publicly (however complex, basic, neat or imperfect it might be). You can search #tidytuesday on social media platforms like LinkedIn to see what other people did with the data.\nThe tidytuesday project github can be found here: https://github.com/rfordatascience/tidytuesday\nIn the data directory you can find every tidytuesday event, complete with data and brief, going back to 2018. The best way to interact with this browser is to use the drop-down tabs on the left-hand side. Selecting any given date directory (e.g., 2022-02-01) will display the readme, which gives the overview and explains how to access the data.",
    "crumbs": [
      "Episode 4 - tidytuesday"
    ]
  },
  {
    "objectID": "episode_4_tidytuesday.html#loading-the-data",
    "href": "episode_4_tidytuesday.html#loading-the-data",
    "title": "Episode 4 Tidy Tuesday",
    "section": "Loading the data",
    "text": "Loading the data\nIn this instance we will load the data from 2024-12-10 (December 10th, 2024). The dataset is perfume data - perfume brands, names, ratings, concentrations, and the different aromas people detect in the perfumes.\n\n\n\n\n\n\n\n\nTo learn more about this dataset, visit: https://github.com/rfordatascience/tidytuesday/blob/main/data/2024/2024-12-10/readme.md",
    "crumbs": [
      "Episode 4 - tidytuesday"
    ]
  },
  {
    "objectID": "episode_4_tidytuesday.html#explore-the-data",
    "href": "episode_4_tidytuesday.html#explore-the-data",
    "title": "Episode 4 Tidy Tuesday",
    "section": "Explore the data",
    "text": "Explore the data\nThis is a totally unknown dataset. When we don’t know anything at all about the data, I find functions like colnames(), head(), and summary() to be a really useful place to start.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat other functions do you normally use for looking at a fresh dataset? I’ve noticed that people tend to develop their favourites, highlighting the different ways we all think about data.\n\n\n\n\n\n\n\n\nThere are a lot of possibilities in terms of visualizations here. We could look at what notes appear most frequently (what aromas people are detecting), the concentrations of different perfumes, or the names of the different perfumes.\nAs an amateur in the perfume world, I’m asking what brands reliably score highly ratings.",
    "crumbs": [
      "Episode 4 - tidytuesday"
    ]
  },
  {
    "objectID": "episode_4_tidytuesday.html#brand-ratings",
    "href": "episode_4_tidytuesday.html#brand-ratings",
    "title": "Episode 4 Tidy Tuesday",
    "section": "Brand ratings",
    "text": "Brand ratings\nI will use the group_by() function to group perfumes into brands, the summarize function to calculate an average (mean) rating score, and a combination of arrange() and desc() to sort brands based on their mean scores.\n\n\n\n\n\n\n\n\nHmmm - two brands have a 10/10 rating (at least, I know from the summarize() function that the max rating is 10, and therefore I’m assuming it’s out of 10). I also know from summarize that the rating count (the number of times the perfume was rated) ranges from 2 - 2,732, with a median of 19 and a mean of 60. I’m concerned that a 10/10 rating could come about from a brand having only a single perfume that was rated twice.\nBefore going any further, let’s visualize the relationship between average rating and rating count:\n\n\n\n\n\n\n\n\nIt seems there is a relationship between Rating_Value and Rating_Count - one we can probably conceptualize quite well! Scents with fewer ratings exhibit the highest and lowest values, while scents with more ratings are gravitating towards a point just below 7.5. The mean and median Rating_Value is 7.35 and 7.40 respectively. It makes sense that as the number of ratings increases, the average rating converges on a middle-ground, smoothing over the person-to-person preferences for scents. I think this is reasonable grounds to filter our data based on a Rating_Count threshold.\nI’ll add in a filter() step, keeping only rows with a rating_count value that is greater than or equal to the median of 19. With this filter, I can be somewhat confident that ratings are not going to be down to individual preferences for scent.\n\nWhich brands have the highest rating across their perfumes?\n\n\n\n\n\n\n\n\nI can see an issue here - some of these brands have only one or two perfumes. Conceivably, it would be difficult for brands with e.g., 100 perfumes to consistently receive such high ratings, and they will therefore not show up in this list. This is essentially the same issue dealt with above - having fewer ratings, or fewer products, means an average score can be skewed.\nTo deal with this, I’ve added an arbitrary filtering threshold for a brand to have 20 or more perfumes in order to be considered.",
    "crumbs": [
      "Episode 4 - tidytuesday"
    ]
  },
  {
    "objectID": "episode_4_tidytuesday.html#visualizing-brand-ratings",
    "href": "episode_4_tidytuesday.html#visualizing-brand-ratings",
    "title": "Episode 4 Tidy Tuesday",
    "section": "Visualizing brand ratings",
    "text": "Visualizing brand ratings\nFirst, I have a ‘basic’ visualization of brand ratings. If you are new to ggplot, there’s a fair amount going on here, but not much more than what was covered in Episode 1.\n\n\n\n\n\n\n\n\n\nImproving the visuals\nWhat can I do to enhance the visuals to be cleaner, more dynamic, more eye-catching, more aesthetic? Is there any other data I can include to improve the plot?\nThinking back to my earlier filtering based on rating count, I realize what I’m doing is placing a higher weighting on perfumes that have been rated more often. I would like to be able to see rating count in my plot.",
    "crumbs": [
      "Episode 4 - tidytuesday"
    ]
  },
  {
    "objectID": "episode_4_tidytuesday.html#conclusions",
    "href": "episode_4_tidytuesday.html#conclusions",
    "title": "Episode 4 Tidy Tuesday",
    "section": "Conclusions",
    "text": "Conclusions\nInitially I wasn’t utilising colour mapping for anything useful, but then added colour as a way to visualize the total number of ratings (not shown here), and eventually average number of ratings. Total number of ratings showed Roja Parfums, Chanel, and Guerlain as positive outliers with a high number of ratings relative to the other 17 brands. Average number of ratings shows that while Ensar Oud / Oriscent have the highest average brand rating, Roja Parfums and Chanel have a much higher average number of ratings, which further supports them as a good brand to choose.\nAs a data story, I really like this: based on Brand rating alone, one might choose Ensar Oud, but with a more full picture, I’d personally be inclined to choose Roja Parfums or Chanel - the difference in Brand rating between them and Ensar Oud is very small, but with Chanel there are approximately five times as many ratings, giving the overall brand rating much more weight.",
    "crumbs": [
      "Episode 4 - tidytuesday"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Into the tidyverse",
    "section": "",
    "text": "Maybe this is your first encounter with R, or maybe you’ve self-taught and stumbled your way through a plot, or maybe you’ve been using base R for ages and you want to pick up some of the tidyverse (that’s where I fit in, by the way). Whatever your situation, this workshop is going to introduce you to the tidyverse, get you started with some exercises, and then set you loose with enough tools to explore things comfortably (and safely) on your own.",
    "crumbs": [
      "Into the tidyverse"
    ]
  },
  {
    "objectID": "episode_2_dataTransformations.html",
    "href": "episode_2_dataTransformations.html",
    "title": "Episode 2 Transforming your data",
    "section": "",
    "text": "In this episode we will see how a small number of functions can be used to transform your data. What do we mean by transform? When we receive raw data we often need to perform some basic tidying, sorting, or trimming to get it into a format that is clean and easy for us to work with.\nTransforming data can involve:\nWe can do all of these transformations using a small number of functions from the dplyr package. The dplyr functions are sometimes referred to as ‘verbs’, since they have descriptive names that identify what the function does.",
    "crumbs": [
      "Episode 2 - Data Transformations"
    ]
  },
  {
    "objectID": "episode_2_dataTransformations.html#the-dplyr-verbs",
    "href": "episode_2_dataTransformations.html#the-dplyr-verbs",
    "title": "Episode 2 Transforming your data",
    "section": "The dplyr verbs",
    "text": "The dplyr verbs\nTo prevent the feeling of being overwhelmed by new functions, let’s start by listing the functions. To work with rows we only have three: arrange(), filter(), distinct(). To work with columns, we have four: relocate(), select(), rename(), mutate().\nOf these seven new functions, six of them have names that are probably easy to interpret: arrange() and relocate() change the order of rows and columns, filter() and select() keep only certain rows and columns, distinct() returns only unique rows (removes duplicates), and rename() changes the name of columns. Only mutate() is not immediately obvious: mutate creates a new column based on one or more other columns (we can think of the data being mutated into a new form).\nFor each of these seven functions we will look at the basic syntax, how the arguments can be used, and complete some exercises.\nFirst, let’s take a quick look at the dataset we are using for this episode: The Lahman package has a collection of baseball datasets, including batting, pitching and fielding records. We will focus on the pitching records.\n\n\n\n\n\n\n\n\nThis is reasonably representative of a dataset, in that it’s got a lot of column names that don’t immediately mean anything to us. If we wanted to, we could find more details online which will explain everything in the (Lahman package)[https://cran.r-project.org/web/packages/Lahman/Lahman.pdf]. Terms will be explained as we get to them, so don’t feel any pressure to understand what the column names all mean just yet.",
    "crumbs": [
      "Episode 2 - Data Transformations"
    ]
  },
  {
    "objectID": "episode_2_dataTransformations.html#rearranging-the-order",
    "href": "episode_2_dataTransformations.html#rearranging-the-order",
    "title": "Episode 2 Transforming your data",
    "section": "(Re)arranging the order",
    "text": "(Re)arranging the order\nThe arrange() function (for rows) and the relocate() function (for columns) allows us to re-order our data.\n\narrange()\nArrange can take one or more column names as an argument, and then arranges the row order based on the value in that column.\n\n\n\n\n\n\n\n\nThis has arranged our data by yearID, starting with the earliest year first, showing us the records date back to 1871!\nWe can add a second column, in which case arrange() will break ties based on the data in the second column.\n\n\n\n\n\n\n\n\nHere we have arranged by year, and then within year, players are ranked according to their number of wins (W). However, arrange() ranks from smallest to largest (ascending order) as a default, and I’d like to see the highest number of wins at the top of each year. I can do this with the desc() function:\n\n\n\n\n\n\n\n\nNow, yearID is arranged from smallest to largest (ascending) and W is arranged from highest to lowest (descending). This provides us with an important example: Within a function, we can add additional arguments to control how that function works.\n\nExercise\nWhat uses can you think of the arrange() function? Have you had to do something like this before? Did you encounter issues, and does the arrange() function have the same limitations?\n\n\n\nrelocate()\nIf you want to change the order of columns, the relocate() function takes a column name and moves it to another position in the dataset. By default, relocate will place the specified column at the start (left) of the dataset, but we can choose to place it immediately before, or immediately after, another column.\nLet’s move the teamID to the far left (which we will call the start or front of the dataset).\n\n\n\n\n\n\n\n\nWe can also move multiple columns at once:\n\n\n\n\n\n\n\n\nNote: because W, L, G are all next to one another, we could actually have written it as relocate(W:G). Also, columns don’t need to already be next to each other to be moved as a group. relocate(W, L, EBB, R) would move these four columns from their various places to the left most positions (with W ending up on the far left, R being fourth in).\nNotice anything odd about the output of this function? If this has worked correctly, the columns should read: W, L, G, playerID. But, in the code above, we relocated yearID to the left of playerID. Why has it gone back???\nThis raises a crucial point about the dplyr verbs: they do not modify the original data. All the functions we have run so far are only ever taking the data, making the changes, and printing the result to the screen. The original data is never modified. If we want to save a copy of the data in the new format, we need to save that information into an object. In the space below, use the relocate() function to save a new object with the W, L and G columns at the far left.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nwlgPitching &lt;- bbPitching |&gt; relocate(W,L,G) |&gt; head()\n\n\n\n\n\n\nrelocate() cont\nThe relocate() function is more flexible when we start to use the .before and .after arguments. As before, we need to specify the name of the column we want to move, and will then use either .before or .after and state another column name.\n\n\n\n\n\n\n\n\nThe code above is relocating the ERA column, not to the far left as normal, but to immediately after (to the right of) the playerID column.\nUse the relocate() function to get the column names in this order:\nThe first six columns must be in this order: playerID, W, L, G, yearID, teamID, with stint and lgID as the last two columns. The other columns can go in any order. Note: you might end up using more pipes and ______ than currently shown in the exercise box! The exercise box is actually a free space where you can type whatever code you want. Remember to finish with ” |&gt; head() ” to display only the top section of your result!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nThere are two ways (at least) to achieve this outcome.\nFirst, we can move W, L, and G to immediately after playerID, save the output into an intermediate object, and then move stint and lgID to after GIDP.\n\n\n\n\n\n\n\n\n\n\n\nHint 2\n\n\n\n\n\nThat would look something like this:\nintermediateObject &lt;- bbPitching |&gt; relocate(W, L, G, .after = playerID)\nintermediateObject |&gt; relocate(stint, lgID, .after = GIDP)\n\n\n\n\n\n\n\n\n\n\n\nHint 3\n\n\n\n\n\nAnother version of this option is to skip the intermediate object and simply pipe the output from the first function into a second instance of the relocate function, like this:\nbbPitching |&gt; relocate(W, L, G, .after = playerID) |&gt; relocate(stint, lgID, .after = GIDP)\nChaining functions with multiple uses of the pipe is very powerful!\n\n\n\n\n\nConclusions on ordering\nA useful way to remember which function is for rows and which is for columns: the “r”s in arrange are for rows, and the “c” in relocate is for columns. arrange() is functionally a sorting function, while relocate() is more of a manual re-shuffling of the columns.\nRemember that these functions are not changing the original data - and that’s most probably a very good thing! If you do want to keep the changes you are making, consider saving the transformed data into a new object rather than over-writing the original.",
    "crumbs": [
      "Episode 2 - Data Transformations"
    ]
  },
  {
    "objectID": "episode_2_dataTransformations.html#keeping-or-removing-data",
    "href": "episode_2_dataTransformations.html#keeping-or-removing-data",
    "title": "Episode 2 Transforming your data",
    "section": "Keeping or removing data",
    "text": "Keeping or removing data\nThe next two functions we will look at are filter() (for rows) and select() (for columns). In both cases, we will specify which rows or columns we want to keep, and the rest will be discarded. As with the above two functions, we can use the r in filter to remind us of “rows” and the c in select to remind us of “columns”.\n\nfilter()\nfilter() can be used to keep any rows that meet a certain criteria in a given column. We can keep rows with values which are greater than, less than, or equal to a value, and we can use terms like “and” or “or” (e.g., keep any row if the value is greater than 1 or less than -1).\nWe will pipe the data to the filter function, specify a column name to work from, and then set the threshold for inclusion.\n\n\n\n\n\n\n\n\nNote that we have not changed the order of the rows, or anything else about the data, but only rows collected after the year 2000 are included. If we wanted to include the year 2000, we could use:\n\n\n\n\n\n\n\n\n\nAnd / Or\nWe can also combine operators in either the “and” setting or the “or” setting.\nModify the code below to filter for player information from the year (“yearID” column) 2000 until now and for those who played for the BOS (Boston) team (using the “teamID” column).\nNote 1: when we want to specify equals (as in, teamID is equal to BOS), we must use “==” over “=”.\nNote 2: when using == we must put “BOS” in quotation marks.\nNote 3: here we are using “&”, but in some cases “,” can be used to mean and.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nThere are four replacements to make:\n\nSpecify the column: year\nThe operator “greater than or equal to”: &gt;=\nThe year: 2000\nThe teamID: BOS\n\nNote that because BOS is a character, it needs to be in “” marks.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nbbPitching |&gt; filter(yearID &gt;= 2000 & teamID == “BOS”)\n\n\n\n\nWe can also use “or” with two operators, with the | symbol.\n\n\n\n\n\n\n\n\nThis will return all rows where the teamID is “BOS” or is “SFN”.\n\n\n\nselect()\nThe select() function works similarly to filter(), except it defines which columns are kept.\n\nExercise\nHaving worked with arrange(), relocate(), and filter(), see if you work out how select() works. Keep the playerID and teamID, and pipe this to the head() function for display:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nBecause we are keeping two columns we will need to use some form of “and”. You might want to try “&”, but for select() we need to use “,” to separate the columns we want.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nbbPitching |&gt; select(playerID, teamID) |&gt; head()\n\n\n\n\nThe select() function has some alternative syntax that can be useful in certain situations (this is an excellent time to remind you that you don’t need to memorise everything).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nselect() advanced usage\nWe can also use select() to introduce you to a powerful feature of programming languages: the ability to perform pattern matching. We will cover pattern matching another time, but for now we can think of it as not needing to specify the exact name of every single column we want to keep.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise\nWhat if you wanted to select all columns that contained either “R” or “r”?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nWe need to use the “or” key: |\nYou might try\nbbPitching |&gt; select(contains(“R” | “r”)) |&gt; head()\nBut this will fail. Instead of providing the “|” to the contains() function, instead try providing it to the select() function.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nbbPitching |&gt; select(contains(“R”) | contains(“r”)) |&gt; head()\nIn this format, the select() function will return any column that “contains R” or “contains r”.",
    "crumbs": [
      "Episode 2 - Data Transformations"
    ]
  },
  {
    "objectID": "episode_2_dataTransformations.html#mutate",
    "href": "episode_2_dataTransformations.html#mutate",
    "title": "Episode 2 Transforming your data",
    "section": "mutate()",
    "text": "mutate()\nUnlike the other dplyr verbs, the purpose of the mutate() function isn’t immediately obvious from the name. The mutate() function will take information from one or more columns and create a new column to store the data in.\nHere we will calculate a new value, called the winLossRatio, by dividing W by L for each row. The new column will appear to the far right of the dataset.\n\n\n\n\n\n\n\n\nWe can see that this hasn’t worked as planned (or rather, it has worked as we planned, but there were unforeseen outcomes like Inf values).\nIn the space below, use the filter() function to remove any row where W or L is 0, then use the mutate() function to create the new winLossRatio column. Use the head() function to display your results. Feel free to add additional functions and arguments if you think they are useful.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nThe four underscores could be replaced with:\n\nThe bbPitching dataset to be passed.\nThe filter() function, using the “&” argument to set both W and L &gt; 0.\nThe mutate() function, creating winLossRatio by dividing W/L.\nThe head() function.\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nbbPitching |&gt; filter(W &gt; 0 & L &gt; 0) |&gt; mutate(winLossRatio = W/L) |&gt; head()\nOut of interest, you could ask what the highest ratio is with arrange() and tail() (remembering that arrange sorts from smallest to largest by default).\nbbPitching |&gt; filter(W &gt; 0 & L &gt; 0) |&gt; mutate(winLossRatio = W/L, .before = playerID) |&gt; arrange(winLossRatio) |&gt; tail()\nAlternatively, you could use arrange(desc(winLossRatio)) and head().\nHere I’ve also added the .before = argument, which we have seen (along with .after) with the relocate() function.\n\n\n\n\nThe solution to this exercise highlights the fact that mutate has created a new column that we can then apply functions to for further filtering or arranging of the dataset.",
    "crumbs": [
      "Episode 2 - Data Transformations"
    ]
  },
  {
    "objectID": "episode_2_dataTransformations.html#distinct-and-rename",
    "href": "episode_2_dataTransformations.html#distinct-and-rename",
    "title": "Episode 2 Transforming your data",
    "section": "distinct() and rename()",
    "text": "distinct() and rename()\nThese are both useful functions, though compared to mutate() or even arrange(), these functions are quite simple and so will only receive a short note here.\nThe distinct() function will remove any duplicate rows and return the remaining unique (distinct) rows. By supplying two or more column names, we can look for distinct groupings. In the code below, I first use the table() function to determine that there are 19 rows for the first year of recording (1871). I then use the arrange() and head() functions (with an additional argument for the head function) to pass only data from 1871 to the distinct() function. Then, distinct(yearID, teamID) will return only those distinct combinations - revealing the names of the nine teams who were recorded in the first year.\n\n\n\n\n\n\n\n\nThe rename() function takes an existing column name (BAOpp) and replaces it with a supplied name (BattingAverageOpponent):",
    "crumbs": [
      "Episode 2 - Data Transformations"
    ]
  },
  {
    "objectID": "episode_2_dataTransformations.html#conclusions",
    "href": "episode_2_dataTransformations.html#conclusions",
    "title": "Episode 2 Transforming your data",
    "section": "Conclusions",
    "text": "Conclusions\nWith just seven functions you can now keep or discard rows and columns based on a wide variety of options, rearrange and rename rows and columns, and create new columns based on existing data. These dplyr verbs give you a great level of control over your dataset and are the type of function you might expect to use on a regular basis.\nThe final thing to take away from this episode is how easily we can chain together functions to manipulate our data into a form that suits us. With the pipe we can add many steps and they remain human readable: moving from left to right we start with data, we can filter it, calculate a new value, arrange the data, and view a portion of it.\nIn the next episode we will introduce grouping, which will give us even finer control over how our dataset is structured and modified. a",
    "crumbs": [
      "Episode 2 - Data Transformations"
    ]
  },
  {
    "objectID": "episode_3_groups.html",
    "href": "episode_3_groups.html",
    "title": "Episode 3 Groups",
    "section": "",
    "text": "Sometimes we will have a single object that has data for many different groups. This could include many samples from e.g., treatment vs control, or it could be many groups (e.g., three replicates each from many samples). Other examples of groups could include months or years in which data was collected, or distinct physical locations where data was collected.\nWhatever the specifics, group_by() is a function that will allow us to keep all our data in a single object and also recognise the different groups or substructure within the object.\n\n\n\n\n\n\n\n\nFirst, let’s see how we can use the mean function to calculate the average number of games (G) in the dataset:\n\n\n\n\n\n\n\n\n\n\nRemember that for this dataset, each row represents a player’s data. e.g., the first row shows player aardsda01’s 2004 results. They played 11 games for the SFN team, and scored 0 runs (R) (probably because they are a pitcher, rather than a batter).\nNow let’s say I want to calculate the mean number of games for each team. First, I’ll use group_by() on the teamID column. Second, I’ll use the summarize() and mean() functions to generate a new column of data showing the mean number of games for each team.\n\n\n\n\n\n\n\n\nHere, group_by has modified the behaviour of functions that follow. Instead of treating the bbBatting object as a single dataset, every row with the same teamID will be treated as a group, and the summarize function can be used to calculate the mean number of games for each individual teamID.\nThe summarize() function works very similarly to mutate() in that it creates a new column, with a name we define, based on some type of calculation. However, unlike mutate(), the summarize() function returns only the new column, and normally returns only a single value per group.\n\n\n\nWhich year had the highest average number of Runs (the R column) scored? Which year had the lowest average number of runs?\nTreat this as an open book, group exercise - consult each other, your notes from previous lessons, anything you like.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nHint 1\nYou will need to pipe the bbBatting data to the group_by() function, with yearID as the argument.\nPipe this information to summarize(). Within summarize, create a new column name and define it was mean(R).\nTo get the highest and lowest, you will need to rearrange the output of summarize() using a function, and then use separate functions to view the highest and lowest averages.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nHint 2\nPipe the output of summarize() to the arrange() function, then use the head() and tail() function. Alternatively, you can use head() only if you prefer to add the desc() function within arrange().\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nbbBatting |&gt; group_by(yearID) |&gt; summarize(yearlyMeanRuns = mean(R)) |&gt; arrange(yearlyMeanGames) |&gt; head()\n\n\n\n\n\n\n\nPreviously, with the dplyr verbs, we saw that original data is never modified (and this is a principal we should adhere to). It is worth noting that if we save data to a new object after grouping, that grouping substructure is sometimes preserved. Therefore any further functions will be applied in a group-by-group setting. We can explicitly control how groups are preserved using the .groups argument in the summarize() function.\n.groups\n\n“drop” will remove all grouping behaviour, the resulting output will have no groups.\n“drop_last” will remove only the last grouping (e.g., if group_by(Year, Month, Day) was used, Year and Month grouping is preserved and Day is dropped. Note that drop_last is the default behaviour.\n“keep” will keep all grouping.\n“rowwise” will keep rowwise grouping.\n\ndrop, and by default drop_last, are recommended as they:\n\nProvide a clean output.\nPrevent accidental behavior in later operations.\nMakes your code more predictable and easier to understand.\n\nOn point 3., it is clearer if you drop grouping and later regroup when, or if, required.\n\n\n\nSo far we have just looked at using the summarize() function with a single argument, but there is more we can do with this function. Summarize() can create as many summaries as required in a single call. Useful functions within summarize() include:\n\nmean(), median()\nsd(), mad()\nmin(), max()\nfirst(), last(), nth() (these functions will return the first, last or nth value from each group)\nn(), n_distinct() (count the total number of rows, or the total number of distinct/unique rows within the each group)\n\n\n\n\nNow that we’ve seen group_by() and some of the argument summarize() can take, we can use them to get a better understanding of our data.\nAfter using the head() function, I can see that some possible useful grouping categories are the playerID, yearID, teamID, and lgID columns.\nWith these groups, we could use any of the summarize() arguments from above to ask questions about our dataset.\n\n\nWhich player has hit the highest number of Home Runs (HR)? How many Home Runs have they hit in total?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\ngroup_by(), summarize(), sum(), arrange() are useful functions!\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nbbBatting |&gt; group_by(playerID) |&gt; summarize(totalHR = sum(HR)) |&gt; arrange(desc(totalHR)) |&gt; head()\n\n\n\n\nWhat are the top 10 years in terms of total games (G) played?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nThis question is very similar to the question above! Remember that when we use summarize(), we need to define the name of the new column we are creating. That name will be used later.\nThe head() and print() commands can both take arguments that control how many lines are displayed. head() just takes a number, print takes ” n = “.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nbbBatting |&gt; group_by(yearID) |&gt; summarize(totalGames = sum(G)) |&gt; arrange(desc(totalGames)) |&gt; head(10)\n\n\n\n\nHow many runs have been made in total in the most recent 10 years? How does this compare to the first 10 years?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nThis question has similarities to the question above. You will need to calculate the total number of runs per year, then arrange the output by yearID. Take the top 10 rows with head(10) or print(n = 10), and pipe it to the sum() function.\nIf you are doing the first 10 years, you technically don’t need the arrange() function at all (because the output of group_by will already be in order) - but it’s always better to be clear about what you are doing!\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nbbBatting |&gt; group_by(yearID) |&gt; summarize(totalRuns = sum(R)) |&gt; arrange(desc(yearID)) |&gt; head(10) |&gt; sum()\nbbBatting |&gt; group_by(yearID) |&gt; summarize(totalRuns = sum(R)) |&gt; arrange(desc(yearID)) |&gt; tail(10) |&gt; sum()\nNote because I argue above that it’s worth being clear and keeping the arrange function even when calculating the first 10 years, I could remove the desc() function within arrange() and the rows would be ordered from smallest (earliest) to largest (most recent). However, in the interest of clarity I think it’s much easier to differentiate the two rows when the change is nearer the end, so I’ve switched out head(10) for tail(10).\n\n\n\n\nIn the free space below, try out some other groups and summarize results. See if you can find anything interesting!",
    "crumbs": [
      "Episode 3 - Grouping"
    ]
  },
  {
    "objectID": "episode_3_groups.html#the-group_by-function",
    "href": "episode_3_groups.html#the-group_by-function",
    "title": "Episode 3 Groups",
    "section": "",
    "text": "Sometimes we will have a single object that has data for many different groups. This could include many samples from e.g., treatment vs control, or it could be many groups (e.g., three replicates each from many samples). Other examples of groups could include months or years in which data was collected, or distinct physical locations where data was collected.\nWhatever the specifics, group_by() is a function that will allow us to keep all our data in a single object and also recognise the different groups or substructure within the object.\n\n\n\n\n\n\n\n\nFirst, let’s see how we can use the mean function to calculate the average number of games (G) in the dataset:\n\n\n\n\n\n\n\n\n\n\nRemember that for this dataset, each row represents a player’s data. e.g., the first row shows player aardsda01’s 2004 results. They played 11 games for the SFN team, and scored 0 runs (R) (probably because they are a pitcher, rather than a batter).\nNow let’s say I want to calculate the mean number of games for each team. First, I’ll use group_by() on the teamID column. Second, I’ll use the summarize() and mean() functions to generate a new column of data showing the mean number of games for each team.\n\n\n\n\n\n\n\n\nHere, group_by has modified the behaviour of functions that follow. Instead of treating the bbBatting object as a single dataset, every row with the same teamID will be treated as a group, and the summarize function can be used to calculate the mean number of games for each individual teamID.\nThe summarize() function works very similarly to mutate() in that it creates a new column, with a name we define, based on some type of calculation. However, unlike mutate(), the summarize() function returns only the new column, and normally returns only a single value per group.\n\n\n\nWhich year had the highest average number of Runs (the R column) scored? Which year had the lowest average number of runs?\nTreat this as an open book, group exercise - consult each other, your notes from previous lessons, anything you like.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nHint 1\nYou will need to pipe the bbBatting data to the group_by() function, with yearID as the argument.\nPipe this information to summarize(). Within summarize, create a new column name and define it was mean(R).\nTo get the highest and lowest, you will need to rearrange the output of summarize() using a function, and then use separate functions to view the highest and lowest averages.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nHint 2\nPipe the output of summarize() to the arrange() function, then use the head() and tail() function. Alternatively, you can use head() only if you prefer to add the desc() function within arrange().\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nbbBatting |&gt; group_by(yearID) |&gt; summarize(yearlyMeanRuns = mean(R)) |&gt; arrange(yearlyMeanGames) |&gt; head()\n\n\n\n\n\n\n\nPreviously, with the dplyr verbs, we saw that original data is never modified (and this is a principal we should adhere to). It is worth noting that if we save data to a new object after grouping, that grouping substructure is sometimes preserved. Therefore any further functions will be applied in a group-by-group setting. We can explicitly control how groups are preserved using the .groups argument in the summarize() function.\n.groups\n\n“drop” will remove all grouping behaviour, the resulting output will have no groups.\n“drop_last” will remove only the last grouping (e.g., if group_by(Year, Month, Day) was used, Year and Month grouping is preserved and Day is dropped. Note that drop_last is the default behaviour.\n“keep” will keep all grouping.\n“rowwise” will keep rowwise grouping.\n\ndrop, and by default drop_last, are recommended as they:\n\nProvide a clean output.\nPrevent accidental behavior in later operations.\nMakes your code more predictable and easier to understand.\n\nOn point 3., it is clearer if you drop grouping and later regroup when, or if, required.\n\n\n\nSo far we have just looked at using the summarize() function with a single argument, but there is more we can do with this function. Summarize() can create as many summaries as required in a single call. Useful functions within summarize() include:\n\nmean(), median()\nsd(), mad()\nmin(), max()\nfirst(), last(), nth() (these functions will return the first, last or nth value from each group)\nn(), n_distinct() (count the total number of rows, or the total number of distinct/unique rows within the each group)\n\n\n\n\nNow that we’ve seen group_by() and some of the argument summarize() can take, we can use them to get a better understanding of our data.\nAfter using the head() function, I can see that some possible useful grouping categories are the playerID, yearID, teamID, and lgID columns.\nWith these groups, we could use any of the summarize() arguments from above to ask questions about our dataset.\n\n\nWhich player has hit the highest number of Home Runs (HR)? How many Home Runs have they hit in total?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\ngroup_by(), summarize(), sum(), arrange() are useful functions!\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nbbBatting |&gt; group_by(playerID) |&gt; summarize(totalHR = sum(HR)) |&gt; arrange(desc(totalHR)) |&gt; head()\n\n\n\n\nWhat are the top 10 years in terms of total games (G) played?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nThis question is very similar to the question above! Remember that when we use summarize(), we need to define the name of the new column we are creating. That name will be used later.\nThe head() and print() commands can both take arguments that control how many lines are displayed. head() just takes a number, print takes ” n = “.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nbbBatting |&gt; group_by(yearID) |&gt; summarize(totalGames = sum(G)) |&gt; arrange(desc(totalGames)) |&gt; head(10)\n\n\n\n\nHow many runs have been made in total in the most recent 10 years? How does this compare to the first 10 years?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nThis question has similarities to the question above. You will need to calculate the total number of runs per year, then arrange the output by yearID. Take the top 10 rows with head(10) or print(n = 10), and pipe it to the sum() function.\nIf you are doing the first 10 years, you technically don’t need the arrange() function at all (because the output of group_by will already be in order) - but it’s always better to be clear about what you are doing!\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nbbBatting |&gt; group_by(yearID) |&gt; summarize(totalRuns = sum(R)) |&gt; arrange(desc(yearID)) |&gt; head(10) |&gt; sum()\nbbBatting |&gt; group_by(yearID) |&gt; summarize(totalRuns = sum(R)) |&gt; arrange(desc(yearID)) |&gt; tail(10) |&gt; sum()\nNote because I argue above that it’s worth being clear and keeping the arrange function even when calculating the first 10 years, I could remove the desc() function within arrange() and the rows would be ordered from smallest (earliest) to largest (most recent). However, in the interest of clarity I think it’s much easier to differentiate the two rows when the change is nearer the end, so I’ve switched out head(10) for tail(10).\n\n\n\n\nIn the free space below, try out some other groups and summarize results. See if you can find anything interesting!",
    "crumbs": [
      "Episode 3 - Grouping"
    ]
  },
  {
    "objectID": "episode_3_groups.html#use-of-slice",
    "href": "episode_3_groups.html#use-of-slice",
    "title": "Episode 3 Groups",
    "section": "Use of slice()",
    "text": "Use of slice()\nThe slice() functions provides a useful set of tools for interacting with certain rows within each group.\nslice_head(n = 1) will return the first row of each group. For example, I can group by yearID, arrange the rows within years by Games played (descending), and then use slice_head(n = 1) to return the player (row) with the highest number of games played for each year:\n\n\n\n\n\n\n\n\nslice_tail(n = 1) will return the last row of each group.\nIf, like in the example above, we are looking for the highest or lowest number, we can instead use slice_min() or slice_max(). Both of these arguments require us to specify the column name we want the min/max value from, and as above, we can specify the number of rows we return with n = 1.\nThis code will return the earliest (min) year a player has a record.\n\n\n\n\n\n\n\n\n\nExercise\nWhich team has scored the highest number of Home Runs (HR) in a year?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nHint 1\nWe can group by teamID, use slice_max, and then use arrange(desc). What column would this be applied to?\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nHint 2\nbbBatting |&gt; group_by(teamID) |&gt; slice_max(HR,n = 1) |&gt; arrange(desc(HR))\nThis code can achieve what we want….but it’s actually a trick question! Can you think of an easier way to get the same answer?\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nbbBatting |&gt; arrange(HR) |&gt; tail()\nIt’s critical to think carefully about what our code is doing at all times, but more importantly to think about how our code relates to our question. Using group_by() and slice_max() works just fine, but it’s important to realise that our question - which team has the highest number of HR - is really only about the HR column, and by arranging the dataset on HR we can find our answer.\n\n\n\n\nNote: slice_min() and slice_max() keep ties! It is therefore possible to end up with more rows than you have groups. You can use the with_ties = False argument to remove this behaviour.",
    "crumbs": [
      "Episode 3 - Grouping"
    ]
  },
  {
    "objectID": "episode_3_groups.html#conclusions",
    "href": "episode_3_groups.html#conclusions",
    "title": "Episode 3 Groups",
    "section": "Conclusions",
    "text": "Conclusions\ngroup_by() is a very powerful function that gives you additional control over your dataset and the dplyr verbs.\nWith group_by() we can analyse a dataset all at once while preserving internal substructure, calculating a range of useful summary statistics for each individual group with the summarize() function. The slice_() functions let us easily view individual rows from each group, which is useful for identifying min/max values per group and also for viewing a cross section of the data to verify it looks as expected.",
    "crumbs": [
      "Episode 3 - Grouping"
    ]
  },
  {
    "objectID": "episode_1_functions.html",
    "href": "episode_1_functions.html",
    "title": "Episode 1 - Functions",
    "section": "",
    "text": "R has two building blocks. Objects, which we can think of as files, and Functions, which we can think of as “things that do things”. Do you want to calculate the mean of some numbers? There’s a function for that. Do you want to count the number of times a name has appeared in a list? There’s a function for that. Do you want to identify differentially expressed genes in an RNA-seq experiment? There’s a function for that too, but I will say up front that you’ll need to spend some time getting your data into the right format before that function will work.",
    "crumbs": [
      "Episode 1 - Functions"
    ]
  },
  {
    "objectID": "episode_1_functions.html#format-of-a-function",
    "href": "episode_1_functions.html#format-of-a-function",
    "title": "Episode 1 - Functions",
    "section": "Format of a function",
    "text": "Format of a function\n\n\n\n\n\n\n\n\nFunctions have a name and are always followed by a set of round brackets. Inside the round brackets is the target of the function. Here, we have used the library() function to load a package (you can think of a package as being like an app, which usually contains more functions and sometimes some example data). The package we have loaded is called palmerpenguins, which is a collection of data about penguins. The data is stored as an object called penguins. We can use functions to look at the penguins object:",
    "crumbs": [
      "Episode 1 - Functions"
    ]
  },
  {
    "objectID": "episode_1_functions.html#the-pipe",
    "href": "episode_1_functions.html#the-pipe",
    "title": "Episode 1 - Functions",
    "section": "The pipe",
    "text": "The pipe\nBefore we go any further, let’s look at a slightly better way to use functions, which uses the “pipe”.\n\n\n\n\n\n\n\n\nIn this format we start with the data, and we pipe it to a function.\nThere are a lot of different functions we can use to view our data. Try some of these functions out for yourself, and see if you can figure out what each function is doing. It’s worth typing these manually to develop muscle memory. Functions to try:\n\nhead()\ntail()\nstr()\nsummary()\ndim()\n\nIn the space below, after the |&gt;, delete the ______ and type a function from above, then click the “Run Code” button on blue. If you make a mistake, you can always click “Start Over” to refresh the box.\n\n\n\n\n\n\n\n\nWhat do you notice about the output of each of these functions? What have you learned about the penguin data so far?\n\nHelp!\nWhenever you encounter a function and you don’t know what it’s doing, you can always ask for help. In the box below, try typing ?head(). This will give you a readout of the manual page for the head() function. These can be dense, but the Description can be informative.\n\n\n\n\n\n\n\n\nAfter the Description there is some example code, and below that is a section called Arguments. So far, we’ve only been giving functions the one argument they require (usually, this is a target, like some data). But functions can usually accept additional arguments that modify precisely how the function works. Let’s look at the head function, which normally returns the top six rows of an object. Within the head() function, we can specify the number of rows we want to see with the “n =” argument:\n\n\n\n\n\n\n\n\nThere are two key takeaways here:\n\nWith arguments we can alter and control how a function works. This can be as small as changing the number of rows we see, or it can be as significant as changing a method! (e.g., we can specify whether adjusted p values are calculated with the FDR or Bonferroni method).\nFunctions have default arguments, and we often don’t see them! For example, the head() function uses n = 6 as a default, and unless we check, we wouldn’t know that. When you become more familiar with functions, it’s worth glancing at the function manual to get an idea of what arguments are being used as defaults.\n\n\n\nThe pipe, continued\nWriting functions using the pipe format, where data is specified first and then passed to a function, results in code that is very clear and easy to read. This is truly apparent when we start to do more complex things with our data, specifically when we incorporate more than one function.\nLet’s say I want to remove all the NAs in the bill_length_mm column, then round the values to the nearest whole number, then check that’s worked by viewing the first 6 values. With the pipe, we start with the data and read from left to right:\n\n\n\n\n\n\n\n\nEasy, right! We read from left to right, and we can track what is happening at each step as it’s separated by the pipe.\nWhat would this code look like without the pipe, where we put the target inside the function? In this case, we have to ‘nest’ the functions within one another, and to make sense of it we need to read from the inside out.\n\n\n\n\n\n\n\n\nReadable, when you have plenty of experience in R. You’ll probably see plenty of code like this online - it’s not wrong, and many people (me included) learned to write like this. Hopefully you find the tidyverse style, combined with the pipe, makes reading and writing code a lot easier.",
    "crumbs": [
      "Episode 1 - Functions"
    ]
  },
  {
    "objectID": "episode_1_functions.html#specifying-data-columns",
    "href": "episode_1_functions.html#specifying-data-columns",
    "title": "Episode 1 - Functions",
    "section": "Specifying data columns",
    "text": "Specifying data columns\nNotice in the above code the use of the “$” sign? It’s used to specify the name of a column in a 2D object (like the penguins object). We can use the column names to directly and specifically refer to a column in an object. You’ll see that you can also use values (i.e., you can say “give me column 3”)….but this runs into issues if you end up changing the order or number of columns. Column names and the $ are a clear and unabiguous way of specifying data\nUse the colnames() function (and the pipe, of course) to see the column names of the penguins object:\n\n\n\n\n\n\n\n\nWe can also type penguins and the “$” symbol and RStudio will prompt us with a dropdown menu of column names. We can narrow this down by typing the first few letters of the column name we want. In your own console, type penguins$ and use the dropdown to select a column, and pass that data to the head() function with the pipe. If the output looks like a numerical value, pass that column data to the mean() function to calculate the mean. You’ll probably need to pass the data to na.omit() first!",
    "crumbs": [
      "Episode 1 - Functions"
    ]
  },
  {
    "objectID": "episode_1_functions.html#exploratory-data-analysis",
    "href": "episode_1_functions.html#exploratory-data-analysis",
    "title": "Episode 1 - Functions",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nExploratory data analysis is a broad term for familiarising yourself with your data. You’re attempting to ‘get a feel’ for the data. Is it normally distributed? Are any samples clear outliers? Is there missing data? It can take a lot of forms, and is a real skill. To start with, let’s practice visualising different groups within the data.\nTo decide where to start, let’s first use the summary function to get an overview of the penguins object:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nRemember to start with the penguins object, then use the pipe to pass the data to the summary() function.\npenguins |&gt; summary()\n\n\n\n\nFrom here I can think about what types of plots we can create. Based on this summary I could plot:\n\nCorrelation (scatter plots) for combinations of bill length, bill depth, flipper length, and body mass.\nBoxplots showing any measurement (e.g., bill depth) grouped by sex, island, species, or year.\nCombinations of these plots.\n\n\nRemoving NAs and creating objects\nI can see in the summary output that there are NAs in the dataset. These will possibly cause small issues downstream, so I’ll take the precaution of removing them all here. Note that removing NAs is a reasonably drastic step and isn’t something to do lightly when working with your own data.\n\n\n\n\n\n\n\n\nHere we have used the “&lt;-” to assign the output from na.omit() into a new object. Note that we don’t get any confirmation that this line of code has executed, so it’s worth double-checking this has been successful with the head() function. If you are working in an RStudio environment (i.e., not a website) you will have an R “environment” in the top right of the screen showing all your objects.\n\n\nPlotting bill length with ggplot2\nMost modern R workshops include a section on the Grammer of Graphics, or the ggplot2 function. ggplot2 is a way to create visualisations within the tidyverse. It can seem overwhelming at first, but once you recognise the template that all plots are built on, it will become quick and easy to create a variety of plots with different data types with minimal extra work.\nThe format for the ggplot2 template is as follows:\n\nspecify the data\nmap variables e.g., map a column the x axis\ncreate the plot\n\n\n\n\n\n\n\n\n\nSome things to note about the format:\n\nIndentations are important. We use new lines and tabs to keep the code organised. Generally you’ll want to specify only one thing per line (e.g., data, x axis and y axis get there own lines).\nThe ggplot formula is a slight break away from the use of pipes.\nThere are actually two separate functions here: the ggplot() function, which is used to specify the data and map the variables, and the geom_boxplot() function which is used to create the actual plot. Because we want these two functions to work together, at the very end of the ggplot() function, we have added a “+” symbol. RStudio interprets this to mean “Ok, the ggplot function has finished, but I need to read it in the context of the next function”.\ngeom_boxplot() is the function for making boxplots. To make a bar plot we would use geom_bar(), to make a scatter plot we use geom_point() etc.,. Type geom_ in the console and scroll the dropdown menu to see the different geom types - there are plenty!\n\nUse the code block below, remove the hash symbols then fill in any variable for the x and the y axis. See how the plots change. Can you create any combinations that are non-sensical, or do not work? Rather than copy-pasting, try and type out the full code each time (this will build muscle memory and make remembering the ggplot template easier).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nRemember that data = must be filled in with penData. For x and y, you can choose any column name listed by colnames() above.\n\n\n\n\n\n\nExtending ggplot2\nSo far we have made (or broken!) a couple of basic plots. Let’s extend our ggplot2 template to include some useful information like a title and a way to control the axes labels.\nFirst, fill in the aes() function arguments: map the island variable to the x axis, and the bill_length_mm variable to the y axis:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nAes requires that you fill in both x and y, and assign a variable to each one. The format is “x = island”.\n\n\n\n\nA useful thing we can do is to make data points different colours based on another variable. To do this, we can add more to the mapping function. Remember that mapping involves taking a variable and associating it with a feature on the plot - that can be the x axis, y axis, or it can colour. Below, we will add “colour = island” within the mapping function. This will assign the island variable to colour.\n\n\n\n\n\n\n\n\nWhere this gets really interesting is when we map colour = species (instead of colour = island). Now we are able to plot an additional variable, treating colour as a new axis to differentiate the data:\n\n\n\n\n\n\n\n\nThis new mapping configuration reveals that Adelie penguins are found on all three islands, while Chinstrap and Gentoo are found only on Dream and Biscoe islands respectively. What initially looked like island-specific differences in bill length were actually species-specific differences!\nThis type of discovery is the core concern of exploratory analysis. This information was not easily available to us while the data was in a spreadsheet or table form, but it is immediately apparent when visualised.\n\n\nOther geoms\nLet’s look at another common type of plot: the scatter plot. To create the scatter plot we need to select two continuous variables (e.g., do not use categorical variables such as sex, island, or species). We will replace geom_boxplot with the new geom_point() function, and in the arguments for this function we will add size (the size of the data point) and alpha (how opaque/transparent the point is). You will need to fill in the missing information first.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nThe ggplot function has two arguments:\n\ndata\nmapping\n\n\n\n\n\nWhat do you notice when looking at this plot? (Other than how pleasantly aesthetic the default colours are in ggplot2).\nPerhaps, like me, you have a vague sense that there are two different groups here. This could be because of the distribution of the data points - it looks like there is a cluster of less-well correlated points in the bottom left, and a second, more tightly correlated group in the top right.\nOne clue comes from colouring the points by sex - we see a repeating pattern from bottom left to top right, which starts with a cluster of females, then a cluster of males, then another cluster of females, and another cluster of males. In many bird species the male is on average heavier than the female (although, the opposite is true in many raptor species), so it is strange to see a sub-cluster of females that are heavier than a sub-cluster of males.\n\nExercise\nRecreate the plot above, but this time, change colour = sex to colour = species. Add in a new mapping argument shape = sex so that we can view both sex and species at the same time.\n\n\n\n\n\n\n\n\nWe had the advantage of knowing that species contributes to differences in bill length, thanks to our earlier plot, so we probably would have known to colour our samples by species, but in the future we might not be aware of sub-structures within our data. Learning to spot trends (like a group being heterogenous) is an important skill to train.\nClear your digital workspace so that you cannot see the code used to create the previous plots. Now, run penData |&gt; summary() to see the data you are working with. Working only from memory, make a new scatter plot that maps bill_depth_mm to the x axis and flipper_length_mm to the y axis.\nIf you are unable to perfectly recreate the code from memory - that’s very normal! Get as far as you can and attempt to run the code. Use the hints when you need to, and the final solution is available.\nFinally, note down some general conclusions about the data based on your new visualisation.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nThe first function is ggplot, and it requires two arguments: data, and mapping.\nMapping will involve starting the aes function which holds the x, y, colour, and shape variables.\n\n\n\n\n\n\n\n\n\n\n\nHint 2\n\n\n\n\n\nAfter the ggplot() function is complete, the “+” symbol tells R that there’s another function incoming.\nThe second function defines the type of plot: in this case geom_point(), which is taking arguments for size and alpha.\nBecause we have another function coming after geom_point(), remember to add a “+” at the end of the line!\n\n\n\n\n\n\n\n\n\n\n\nHint 3\n\n\n\n\n\nWe have two functions to add labels and a title:\nlabs(), which adds a label to the x and the y axis (and is followed by a “+” symbol, since it’s not the last function).\nggtitle(), which adds a title. Since this is finally the last function, no + is needed.\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nFully worked solution:\nggplot(data = penData,\n   mapping = aes(x = bill_length_mm,\n   \n                 y = flipper_length_mm,\n                 \n                 colour = species,\n                 \n                 shape = sex)) +\n                 \ngeom_point(size = 2, alpha = 0.6) +\nlabs(x = “Bill depth (mm)”,\n   y = \"Flipper length (mm)\") +\n   \nggtitle(“Bill depth vs flipper length”)",
    "crumbs": [
      "Episode 1 - Functions"
    ]
  },
  {
    "objectID": "episode_1_functions.html#the-completed-figure",
    "href": "episode_1_functions.html#the-completed-figure",
    "title": "Episode 1 - Functions",
    "section": "The completed figure",
    "text": "The completed figure\nHere is the complete figure, to which we have added an additional argument (“scale_colour_viridis(discrete = TRUE)”, plus “library(viridis)”) to change the colour defaults to a more colourblind-friendly palette.\n\n\n\n\n\n\n\n\nYou now have a basic grasp of functions, and appreciate the value of visualising your data.",
    "crumbs": [
      "Episode 1 - Functions"
    ]
  },
  {
    "objectID": "intoTheTidyverse.html",
    "href": "intoTheTidyverse.html",
    "title": "Into the tidyverse",
    "section": "",
    "text": "The tidyverse is a collection of R tools, which we call packages, that were designed to be easy to use, easy to read, and work well together. To understand the tidyverse, we need to know some of the history of R.\n\n\nR was created in 1993 by Ross Ihaka and Robert Gentleman at the University of Auckland. It was designed as a tool to teach statistics, and it’s been widely adopted by the field of biology. Over time many people have developed R packages - packages can be approximately thought as like apps on a phone - which focus on specific analyses. For example, if you want to identify differentially expressed genes using RNA-seq data, there is an R package that can perform various statistical tests and normalisation steps. Actually, there are lots of packages that will do this, and the hard part is choosing which one to use. All of these packages are developed by the community, which is great, and initially they were all written in what we call “base R”.\nBase R, and all the R packages that were developed using it, are a bit like the English language: for those who grew up with it, it’s beautifully flexible, expressive, and intuitive. For anyone learning English as an adult…why on earth is there a “g” in night? (Or a “k” in knight, for that matter). Base R packages, like the English language, are a mix of styles and formats depending on who wrote them.\n\n\n\nThe tidyverse is a series of packages that have been designed from the ground up to work together, using a consistent, logical style. It’s written to be human readable, intuitive, and easy to learn. The tidyverse is highly popular and is well documented. My personal opinion: if I was going to learn R now, I would choose to focus on learning the tidyverse.\nThe tidyverse is also a mindset about how data should be presented and stored. Data is “tidy” if:\n\nEach variable is stored in a column (variables could be Age, Height, Occupation).\nEach observation is stored in a row (here, observations could be individuals).\nTogether, these rows and columns form a table.",
    "crumbs": [
      "Welcome to the tidyverse"
    ]
  },
  {
    "objectID": "intoTheTidyverse.html#what-is-the-tidyverse",
    "href": "intoTheTidyverse.html#what-is-the-tidyverse",
    "title": "Into the tidyverse",
    "section": "",
    "text": "The tidyverse is a collection of R tools, which we call packages, that were designed to be easy to use, easy to read, and work well together. To understand the tidyverse, we need to know some of the history of R.\n\n\nR was created in 1993 by Ross Ihaka and Robert Gentleman at the University of Auckland. It was designed as a tool to teach statistics, and it’s been widely adopted by the field of biology. Over time many people have developed R packages - packages can be approximately thought as like apps on a phone - which focus on specific analyses. For example, if you want to identify differentially expressed genes using RNA-seq data, there is an R package that can perform various statistical tests and normalisation steps. Actually, there are lots of packages that will do this, and the hard part is choosing which one to use. All of these packages are developed by the community, which is great, and initially they were all written in what we call “base R”.\nBase R, and all the R packages that were developed using it, are a bit like the English language: for those who grew up with it, it’s beautifully flexible, expressive, and intuitive. For anyone learning English as an adult…why on earth is there a “g” in night? (Or a “k” in knight, for that matter). Base R packages, like the English language, are a mix of styles and formats depending on who wrote them.\n\n\n\nThe tidyverse is a series of packages that have been designed from the ground up to work together, using a consistent, logical style. It’s written to be human readable, intuitive, and easy to learn. The tidyverse is highly popular and is well documented. My personal opinion: if I was going to learn R now, I would choose to focus on learning the tidyverse.\nThe tidyverse is also a mindset about how data should be presented and stored. Data is “tidy” if:\n\nEach variable is stored in a column (variables could be Age, Height, Occupation).\nEach observation is stored in a row (here, observations could be individuals).\nTogether, these rows and columns form a table.",
    "crumbs": [
      "Welcome to the tidyverse"
    ]
  },
  {
    "objectID": "intoTheTidyverse.html#into-the-tidyverse",
    "href": "intoTheTidyverse.html#into-the-tidyverse",
    "title": "Into the tidyverse",
    "section": "Into the tidyverse",
    "text": "Into the tidyverse\nIn this workshop series we will start out assuming you know nothing about R. We will assume that you are either doing this workshop using the live website*. We will first introduce the two building blocks of R: functions and objects. Simultaneously we will look at visualisations and the concept of exploratory data analysis.\nOnce you know what a function is we will look at how functions work in the tidyverse style - this is where we will introduce you to the “pipe”. The pipe, or “piping” is a way to pass information from one function to another.\nThis workshop places a strong focus on practice and repetition through exercises. You are attempting to learn a language, and you can’t do that without practice. Once you have experience with the basics, we will increase the pace and introduce you to a wider toolbox of functions that can be used to achieve your goals.\nThis workshop series draws from R for Data Science, second edition, which should be considered the primary resource for a person learning to work within the tidyverse. It is strongly recommended reading for anyone interested in R and data science.\n*If you are not working on the website, you will need to do some work on your own to get R and RStudio, as well as certain R packages, installed on your computer. These installations may sound intimidating but they can be completed with some reading on google.",
    "crumbs": [
      "Welcome to the tidyverse"
    ]
  }
]