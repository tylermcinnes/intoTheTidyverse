[
  {
    "objectID": "intoTheTidyverse.html",
    "href": "intoTheTidyverse.html",
    "title": "Into the tidyverse",
    "section": "",
    "text": "The tidyverse is a collection of R tools, which we call packages, that were designed to be easy to use, easy to read, and work well together. To understand the tidyverse, we need to know some of the history of R.\n\n\nR was created in 1993 by Ross Ihaka and Robert Gentleman at the University of Auckland. It was designed as a tool to teach statistics, and it’s been widely adopted by the field of biology. Over time many people have developed R packages - packages can be approximately thought as like apps on a phone - which focus on specific analyses. For example, if you want to identify differentially expressed genes using RNA-seq data, there is an R package that can perform various statistical tests and normalisation steps. Actually, there are lots of packages that will do this, and the hard part is choosing which one to use. All of these packages are developed by the community, which is great, and initially they were all written in what we call “base R”.\nBase R, and all the R packages that were developed using it, are a bit like the English language: for those who grew up with it, it’s beautifully flexible, expressive, and intuitive. For anyone learning English as an adult…why on earth is there a “g” in night? (Or a “k” in knight, for that matter). Base R packages, like the English language, are a mix of styles and formats depending on who wrote them.\n\n\n\nThe tidyverse is a series of packages that have been designed from the ground up to work together, using a consistent, logical style. It’s written to be human readable, intuitive, and easy to learn. The tidyverse is highly popular and is well documented. My personal opinion: if I was going to learn R now, I would choose to focus on learning the tidyverse.\nThe tidyverse is also a mindset about how data should be presented and stored. Data is “tidy” if:\n\nEach variable is stored in a column (variables could be Age, Height, Occupation).\nEach observation is stored in a row (here, observations could be individuals).\nTogether, these rows and columns form a table.",
    "crumbs": [
      "Welcome to the tidyverse"
    ]
  },
  {
    "objectID": "intoTheTidyverse.html#what-is-the-tidyverse",
    "href": "intoTheTidyverse.html#what-is-the-tidyverse",
    "title": "Into the tidyverse",
    "section": "",
    "text": "The tidyverse is a collection of R tools, which we call packages, that were designed to be easy to use, easy to read, and work well together. To understand the tidyverse, we need to know some of the history of R.\n\n\nR was created in 1993 by Ross Ihaka and Robert Gentleman at the University of Auckland. It was designed as a tool to teach statistics, and it’s been widely adopted by the field of biology. Over time many people have developed R packages - packages can be approximately thought as like apps on a phone - which focus on specific analyses. For example, if you want to identify differentially expressed genes using RNA-seq data, there is an R package that can perform various statistical tests and normalisation steps. Actually, there are lots of packages that will do this, and the hard part is choosing which one to use. All of these packages are developed by the community, which is great, and initially they were all written in what we call “base R”.\nBase R, and all the R packages that were developed using it, are a bit like the English language: for those who grew up with it, it’s beautifully flexible, expressive, and intuitive. For anyone learning English as an adult…why on earth is there a “g” in night? (Or a “k” in knight, for that matter). Base R packages, like the English language, are a mix of styles and formats depending on who wrote them.\n\n\n\nThe tidyverse is a series of packages that have been designed from the ground up to work together, using a consistent, logical style. It’s written to be human readable, intuitive, and easy to learn. The tidyverse is highly popular and is well documented. My personal opinion: if I was going to learn R now, I would choose to focus on learning the tidyverse.\nThe tidyverse is also a mindset about how data should be presented and stored. Data is “tidy” if:\n\nEach variable is stored in a column (variables could be Age, Height, Occupation).\nEach observation is stored in a row (here, observations could be individuals).\nTogether, these rows and columns form a table.",
    "crumbs": [
      "Welcome to the tidyverse"
    ]
  },
  {
    "objectID": "intoTheTidyverse.html#into-the-tidyverse",
    "href": "intoTheTidyverse.html#into-the-tidyverse",
    "title": "Into the tidyverse",
    "section": "Into the tidyverse",
    "text": "Into the tidyverse\nIn this workshop series we will start out assuming you know nothing about R. We will assume that you are either doing this workshop using the live website*. We will first introduce the two building blocks of R: functions and objects. Simultaneously we will look at visualisations and the concept of exploratory data analysis.\nOnce you know what a function is we will look at how functions work in the tidyverse style - this is where we will introduce you to the “pipe”. The pipe, or “piping” is a way to pass information from one function to another.\nThis workshop places a strong focus on practice and repetition through exercises. You are attempting to learn a language, and you can’t do that without practice. Once you have experience with the basics, we will increase the pace and introduce you to a wider toolbox of functions that can be used to achieve your goals.\nThis workshop series draws from R for Data Science, second edition, which should be considered the primary resource for a person learning to work within the tidyverse. It is strongly recommended reading for anyone interested in R and data science.\n*If you are not working on the website, you will need to do some work on your own to get R and RStudio, as well as certain R packages, installed on your computer. These installations may sound intimidating but they can be completed with some reading on google.",
    "crumbs": [
      "Welcome to the tidyverse"
    ]
  },
  {
    "objectID": "episode_1_functions.html",
    "href": "episode_1_functions.html",
    "title": "Episode 1 - Functions",
    "section": "",
    "text": "R has two building blocks. Objects, which we can think of as files, and Functions, which we can think of as “things that do things”. Do you want to calculate the mean of some numbers? There’s a function for that. Do you want to count the number of times a name has appeared in a list? There’s a function for that. Do you want to identify differentially expressed genes in an RNA-seq experiment? There’s a function for that too, but I will say up front that you’ll need to spend some time getting your data into the right format before that function will work.",
    "crumbs": [
      "Episode 1 - Functions"
    ]
  },
  {
    "objectID": "episode_1_functions.html#format-of-a-function",
    "href": "episode_1_functions.html#format-of-a-function",
    "title": "Episode 1 - Functions",
    "section": "Format of a function",
    "text": "Format of a function\n\n\n\n\n\n\n\n\nFunctions have a name and are always followed by a set of round brackets. Inside the round brackets is the target of the function. Here, we have used the library() function to load a package (you can think of a package as being like an app, which usually contains more functions and sometimes some example data). The package we have loaded is called palmerpenguins, which is a collection of data about penguins. The data is stored as an object called penguins. We can use functions to look at the penguins object:",
    "crumbs": [
      "Episode 1 - Functions"
    ]
  },
  {
    "objectID": "episode_1_functions.html#the-pipe",
    "href": "episode_1_functions.html#the-pipe",
    "title": "Episode 1 - Functions",
    "section": "The pipe",
    "text": "The pipe\nBefore we go any further, let’s look at a slightly better way to use functions, which uses the “pipe”.\n\n\n\n\n\n\n\n\nIn this format we start with the data, and we pipe it to a function.\nThere are a lot of different functions we can use to view our data. Try some of these functions out for yourself, and see if you can figure out what each function is doing. It’s worth typing these manually to develop muscle memory. Functions to try:\n\nhead()\ntail()\nstr()\nsummary()\ndim()\n\nIn the space below, after the |&gt;, delete the ______ and type a function from above, then click the “Run Code” button on blue. If you make a mistake, you can always click “Start Over” to refresh the box.\n\n\n\n\n\n\n\n\nWhat do you notice about the output of each of these functions? What have you learned about the penguin data so far?\n\nHelp!\nWhenever you encounter a function and you don’t know what it’s doing, you can always ask for help. In the box below, try typing ?head(). This will give you a readout of the manual page for the head() function. These can be dense, but the Description can be informative.\n\n\n\n\n\n\n\n\nAfter the Description there is some example code, and below that is a section called Arguments. So far, we’ve only been giving functions the one argument they require (usually, this is a target, like some data). But functions can usually accept additional arguments that modify precisely how the function works. Let’s look at the head function, which normally returns the top six rows of an object. Within the head() function, we can specify the number of rows we want to see with the “n =” argument:\n\n\n\n\n\n\n\n\nThere are two key takeaways here:\n\nWith arguments we can alter and control how a function works. This can be as small as changing the number of rows we see, or it can be as significant as changing a method! (e.g., we can specify whether adjusted p values are calculated with the FDR or Bonferroni method).\nFunctions have default arguments, and we often don’t see them! For example, the head() function uses n = 6 as a default, and unless we check, we wouldn’t know that. When you become more familiar with functions, it’s worth glancing at the function manual to get an idea of what arguments are being used as defaults.\n\n\n\nThe pipe, continued\nWriting functions using the pipe format, where data is specified first and then passed to a function, results in code that is very clear and easy to read. This is truly apparent when we start to do more complex things with our data, specifically when we incorporate more than one function.\nLet’s say I want to remove all the NAs in the bill_length_mm column, then round the values to the nearest whole number, then check that’s worked by viewing the first 6 values. With the pipe, we start with the data and read from left to right:\n\n\n\n\n\n\n\n\nEasy, right! We read from left to right, and we can track what is happening at each step as it’s separated by the pipe.\nWhat would this code look like without the pipe, where we put the target inside the function? In this case, we have to ‘nest’ the functions within one another, and to make sense of it we need to read from the inside out.\n\n\n\n\n\n\n\n\nReadable, when you have plenty of experience in R. You’ll probably see plenty of code like this online - it’s not wrong, and many people (me included) learned to write like this. Hopefully you find the tidyverse style, combined with the pipe, makes reading and writing code a lot easier.",
    "crumbs": [
      "Episode 1 - Functions"
    ]
  },
  {
    "objectID": "episode_1_functions.html#specifying-data-columns",
    "href": "episode_1_functions.html#specifying-data-columns",
    "title": "Episode 1 - Functions",
    "section": "Specifying data columns",
    "text": "Specifying data columns\nNotice in the above code the use of the “$” sign? It’s used to specify the name of a column in a 2D object (like the penguins object). We can use the column names to directly and specifically refer to a column in an object. You’ll see that you can also use values (i.e., you can say “give me column 3”)….but this runs into issues if you end up changing the order or number of columns. Column names and the $ are a clear and unabiguous way of specifying data\nUse the colnames() function (and the pipe, of course) to see the column names of the penguins object:\n\n\n\n\n\n\n\n\nWe can also type penguins and the “$” symbol and RStudio will prompt us with a dropdown menu of column names. We can narrow this down by typing the first few letters of the column name we want. In your own console, type penguins$ and use the dropdown to select a column, and pass that data to the head() function with the pipe. If the output looks like a numerical value, pass that column data to the mean() function to calculate the mean. You’ll probably need to pass the data to na.omit() first!",
    "crumbs": [
      "Episode 1 - Functions"
    ]
  },
  {
    "objectID": "episode_1_functions.html#exploratory-data-analysis",
    "href": "episode_1_functions.html#exploratory-data-analysis",
    "title": "Episode 1 - Functions",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nExploratory data analysis is a broad term for familiarising yourself with your data. You’re attempting to ‘get a feel’ for the data. Is it normally distributed? Are any samples clear outliers? Is there missing data? It can take a lot of forms, and is a real skill. To start with, let’s practice visualising different groups within the data.\nTo decide where to start, let’s first use the summary function to get an overview of the penguins object:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nRemember to start with the penguins object, then use the pipe to pass the data to the summary() function.\npenguins |&gt; summary()\n\n\n\n\nFrom here I can think about what types of plots we can create. Based on this summary I could plot:\n\nCorrelation (scatter plots) for combinations of bill length, bill depth, flipper length, and body mass.\nBoxplots showing any measurement (e.g., bill depth) grouped by sex, island, species, or year.\nCombinations of these plots.\n\n\nRemoving NAs and creating objects\nI can see in the summary output that there are NAs in the dataset. These will possibly cause small issues downstream, so I’ll take the precaution of removing them all here. Note that removing NAs is a reasonably drastic step and isn’t something to do lightly when working with your own data.\n\n\n\n\n\n\n\n\nHere we have used the “&lt;-” to assign the output from na.omit() into a new object. Note that we don’t get any confirmation that this line of code has executed, so it’s worth double-checking this has been successful with the head() function. If you are working in an RStudio environment (i.e., not a website) you will have an R “environment” in the top right of the screen showing all your objects.\n\n\nPlotting bill length with ggplot2\nMost modern R workshops include a section on the Grammer of Graphics, or the ggplot2 function. ggplot2 is a way to create visualisations within the tidyverse. It can seem overwhelming at first, but once you recognise the template that all plots are built on, it will become quick and easy to create a variety of plots with different data types with minimal extra work.\nThe format for the ggplot2 template is as follows:\n\nspecify the data\nmap variables e.g., map a column the x axis\ncreate the plot\n\n\n\n\n\n\n\n\n\nSome things to note about the format:\n\nIndentations are important. We use new lines and tabs to keep the code organised. Generally you’ll want to specify only one thing per line (e.g., data, x axis and y axis get there own lines).\nThe ggplot formula is a slight break away from the use of pipes.\nThere are actually two separate functions here: the ggplot() function, which is used to specify the data and map the variables, and the geom_boxplot() function which is used to create the actual plot. Because we want these two functions to work together, at the very end of the ggplot() function, we have added a “+” symbol. RStudio interprets this to mean “Ok, the ggplot function has finished, but I need to read it in the context of the next function”.\ngeom_boxplot() is the function for making boxplots. To make a bar plot we would use geom_bar(), to make a scatter plot we use geom_point() etc.,. Type geom_ in the console and scroll the dropdown menu to see the different geom types - there are plenty!\n\nUse the code block below, remove the hash symbols then fill in any variable for the x and the y axis. See how the plots change. Can you create any combinations that are non-sensical, or do not work? Rather than copy-pasting, try and type out the full code each time (this will build muscle memory and make remembering the ggplot template easier).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nRemember that data = must be filled in with penData. For x and y, you can choose any column name listed by colnames() above.\n\n\n\n\n\n\nExtending ggplot2\nSo far we have made (or broken!) a couple of basic plots. Let’s extend our ggplot2 template to include some useful information like a title and a way to control the axes labels.\nFirst, fill in the aes() function arguments: map the island variable to the x axis, and the bill_length_mm variable to the y axis:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nAes requires that you fill in both x and y, and assign a variable to each one. The format is “x = island”.\n\n\n\n\nA useful thing we can do is to make data points different colours based on another variable. To do this, we can add more to the mapping function. Remember that mapping involves taking a variable and associating it with a feature on the plot - that can be the x axis, y axis, or it can colour. Below, we will add “colour = island” within the mapping function. This will assign the island variable to colour.\n\n\n\n\n\n\n\n\nWhere this gets really interesting is when we map colour = species (instead of colour = island). Now we are able to plot an additional variable, treating colour as a new axis to differentiate the data:\n\n\n\n\n\n\n\n\nThis new mapping configuration reveals that Adelie penguins are found on all three islands, while Chinstrap and Gentoo are found only on Dream and Biscoe islands respectively. What initially looked like island-specific differences in bill length were actually species-specific differences!\nThis type of discovery is the core concern of exploratory analysis. This information was not easily available to us while the data was in a spreadsheet or table form, but it is immediately apparent when visualised.\n\n\nOther geoms\nLet’s look at another common type of plot: the scatter plot. To create the scatter plot we need to select two continuous variables (e.g., do not use categorical variables such as sex, island, or species). We will replace geom_boxplot with the new geom_point() function, and in the arguments for this function we will add size (the size of the data point) and alpha (how opaque/transparent the point is). You will need to fill in the missing information first.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nThe ggplot function has two arguments:\n\ndata\nmapping\n\n\n\n\n\nWhat do you notice when looking at this plot? (Other than how pleasantly aesthetic the default colours are in ggplot2).\nPerhaps, like me, you have a vague sense that there are two different groups here. This could be because of the distribution of the data points - it looks like there is a cluster of less-well correlated points in the bottom left, and a second, more tightly correlated group in the top right.\nOne clue comes from colouring the points by sex - we see a repeating pattern from bottom left to top right, which starts with a cluster of females, then a cluster of males, then another cluster of females, and another cluster of males. In many bird species the male is on average heavier than the female (although, the opposite is true in many raptor species), so it is strange to see a sub-cluster of females that are heavier than a sub-cluster of males.\n\nExercise\nRecreate the plot above, but this time, change colour = sex to colour = species. Add in a new mapping argument shape = sex so that we can view both sex and species at the same time.\n\n\n\n\n\n\n\n\nWe had the advantage of knowing that species contributes to differences in bill length, thanks to our earlier plot, so we probably would have known to colour our samples by species, but in the future we might not be aware of sub-structures within our data. Learning to spot trends (like a group being heterogenous) is an important skill to train.\nClear your digital workspace so that you cannot see the code used to create the previous plots. Now, run penData |&gt; summary() to see the data you are working with. Working only from memory, make a new scatter plot that maps bill_depth_mm to the x axis and flipper_length_mm to the y axis.\nIf you are unable to perfectly recreate the code from memory - that’s very normal! Get as far as you can and attempt to run the code. Use the hints when you need to, and the final solution is available.\nFinally, note down some general conclusions about the data based on your new visualisation.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nThe first function is ggplot, and it requires two arguments: data, and mapping.\nMapping will involve starting the aes function which holds the x, y, colour, and shape variables.\n\n\n\n\n\n\n\n\n\n\n\nHint 2\n\n\n\n\n\nAfter the ggplot() function is complete, the “+” symbol tells R that there’s another function incoming.\nThe second function defines the type of plot: in this case geom_point(), which is taking arguments for size and alpha.\nBecause we have another function coming after geom_point(), remember to add a “+” at the end of the line!\n\n\n\n\n\n\n\n\n\n\n\nHint 3\n\n\n\n\n\nWe have two functions to add labels and a title:\nlabs(), which adds a label to the x and the y axis (and is followed by a “+” symbol, since it’s not the last function).\nggtitle(), which adds a title. Since this is finally the last function, no + is needed.\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nFully worked solution:\nggplot(data = penData,\n   mapping = aes(x = bill_length_mm,\n   \n                 y = flipper_length_mm,\n                 \n                 colour = species,\n                 \n                 shape = sex)) +\n                 \ngeom_point(size = 2, alpha = 0.6) +\nlabs(x = “Bill depth (mm)”,\n   y = \"Flipper length (mm)\") +\n   \nggtitle(“Bill depth vs flipper length”)",
    "crumbs": [
      "Episode 1 - Functions"
    ]
  },
  {
    "objectID": "episode_1_functions.html#the-completed-figure",
    "href": "episode_1_functions.html#the-completed-figure",
    "title": "Episode 1 - Functions",
    "section": "The completed figure",
    "text": "The completed figure\nHere is the complete figure, to which we have added an additional argument (“scale_colour_viridis(discrete = TRUE)”, plus “library(viridis)”) to change the colour defaults to a more colourblind-friendly palette.\n\n\n\n\n\n\n\n\nYou now have a basic grasp of functions, and appreciate the value of visualising your data.",
    "crumbs": [
      "Episode 1 - Functions"
    ]
  },
  {
    "objectID": "episode_2_dataTransformations.html",
    "href": "episode_2_dataTransformations.html",
    "title": "Episode 2 Transforming your data",
    "section": "",
    "text": "In this episode we will see how a small number of functions can be used to transform your data. What do we mean by transform? When we receive raw data we often need to perform some basic tidying, sorting, or trimming to get it into a format that is clean and easy for us to work with.\nTransforming data can involve:\nWe can do all of these transformations using a small number of functions from the dplyr package. The dplyr functions are sometimes referred to as ‘verbs’, since they have descriptive names that identify what the function does.",
    "crumbs": [
      "Episode 2 - Data Transformations"
    ]
  },
  {
    "objectID": "episode_2_dataTransformations.html#the-dplyr-verbs",
    "href": "episode_2_dataTransformations.html#the-dplyr-verbs",
    "title": "Episode 2 Transforming your data",
    "section": "The dplyr verbs",
    "text": "The dplyr verbs\nTo prevent the feeling of being overwhelmed by new functions, let’s start by listing the functions. To work with rows we only have three: arrange(), filter(), distinct(). To work with columns, we have four: relocate(), select(), rename(), mutate().\nOf these seven new functions, six of them have names that are probably easy to interpret: arrange() and relocate() change the order of rows and columns, filter() and select() keep only certain rows and columns, rename() changes the name of columns. Only mutate() is not immediately obvious: mutate creates a new column based on one or more other columns (we can think of the data being mutated into a new form).\nFor each of these seven functions we will look at the basic syntax, how the arguments can be used, and complete some exercises.\nFirst, let’s take a quick look at the dataset we are using for this episode: The Lahman package has a collection of baseball datasets, including batting, pitching and fielding records. We will focus on the pitching records.\n\n\n\n\n\n\n\n\nThis is reasonably representative of a dataset, in that it’s got a lot of column names that don’t immediately mean anything to us. If we wanted to, we could find more details online which will explain everything in the (Lahman package)[https://cran.r-project.org/web/packages/Lahman/Lahman.pdf]. Terms will be explained as we get to them, so don’t feel any pressure to understand what the column names all mean just yet.",
    "crumbs": [
      "Episode 2 - Data Transformations"
    ]
  },
  {
    "objectID": "episode_2_dataTransformations.html#rearranging-the-order",
    "href": "episode_2_dataTransformations.html#rearranging-the-order",
    "title": "Episode 2 Transforming your data",
    "section": "(Re)arranging the order",
    "text": "(Re)arranging the order\nThe arrange() function (for rows) and the relocate() function (for columns) allows us to re-order our data.\n\narrange()\nArrange can take one or more column names as an argument, and then arranges the row order based on the value in that column.\n\n\n\n\n\n\n\n\nThis has arranged our data by yearID, starting with the earliest year first, showing us the records date back to 1871!\nWe can add a second column, in which case arrange() will break ties based on the data in the second column.\n\n\n\n\n\n\n\n\nHere we have arranged by year, and then within year, players are ranked according to their number of wins (W). However, arrange() ranks from smallest to largest (ascending order) as a default, and I’d like to see the highest number of wins at the top of each year. I can do this with the desc() function:\n\n\n\n\n\n\n\n\nNow, yearID is arranged from smallest to largest (ascending) and W is arranged from highest to lowest (descending). This provides us with an important example: Within a function, we can add additional arguments to control how that function works.\n\nExercise\nWhat uses can you think of the arrange() function? Have you had to do something like this before? Did you encounter issues, and does the arrange() function have the same limitations?\n\n\n\nrelocate()\nIf you want to change the order of columns, the relocate() function takes a column name and moves it to another position in the dataset. By default, relocate will place the specified column at the start (left) of the dataset, but we can choose to place it immediately before, or immediately after, another column.\nLet’s move the teamID to the far left (which we will call the start or front of the dataset).\n\n\n\n\n\n\n\n\nWe can also move multiple columns at once:\n\n\n\n\n\n\n\n\nNote: because W, L, G are all next to one another, we could actually have written it as relocate(W:G). Also, columns don’t need to already be next to each other to be moved as a group. relocate(W, L, EBB, R) would move these four columns from their various places to the left most positions (with W ending up on the far left, R being fourth in).\nNotice anything odd about the output of this function? If this has worked correctly, the columns should read: W, L, G, playerID. But, in the code above, we relocated yearID to the left of playerID. Why has it gone back???\nThis raises a crucial point about the dplyr verbs: they do not modify the original data. All the functions we have run so far are only ever taking the data, making the changes, and printing the result to the screen. The original data is never modified. If we want to save a copy of the data in the new format, we need to save that information into an object. In the space below, use the relocate() function to save a new object with the W, L and G columns at the far left.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nwlgPitching &lt;- bbPitching |&gt; relocate(W,L,G) |&gt; head()\n\n\n\n\n\n\nrelocate() cont\nThe relocate() function is more flexible when we start to use the .before and .after arguments. As before, we need to specify the name of the column we want to move, and will then use either .before or .after and state another column name.\n\n\n\n\n\n\n\n\nUse the relocate() function to get the column names in this order:\nThe first six columns must be in this order: playerID, W, L, G, yearID, teamID, with stint and lgID as the last two columns The other columns can go in any order.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nThere are two ways (at least) to achieve this outcome.\nFirst, we can move W, L, and G to immediately after playerID, save the output into an intermediate object, and then move stint and lgID to after GIDP.\n\n\n\n\n\n\n\n\n\n\n\nHint 2\n\n\n\n\n\nThat would look something like this:\nintermediateObject &lt;- bbPitching |&gt; relocate(W, L, G, .after = playerID)\nintermediateObject |&gt; relocate(stint, lgID, .after = GIDP)\n\n\n\n\n\n\n\n\n\n\n\nHint 3\n\n\n\n\n\nAnother version of this option is to skip the intermediate object and simply pipe the output from the first function into a second instance of the relocate function, like this:\nbbPitching |&gt; relocate(W, L, G, .after = playerID) |&gt; relocate(stint, lgID, .after = GIDP)\nChaining functions with multiple uses of the pipe is very powerful!\n\n\n\n\n\nConclusions on ordering\nA useful way to remember which function is for rows and which is for columns: the “r”s in arrange are for rows, and the “c” in relocate is for columns. arrange() is functionally a sorting function, while relocate() is more of a manual re-shuffling of the columns.\nRemember that these functions are not changing the original data - and that’s most probably a very good thing! If you do want to keep the changes you are making, consider saving the transformed data into a new object rather than over-writing the original.",
    "crumbs": [
      "Episode 2 - Data Transformations"
    ]
  },
  {
    "objectID": "episode_2_dataTransformations.html#keeping-or-removing-data",
    "href": "episode_2_dataTransformations.html#keeping-or-removing-data",
    "title": "Episode 2 Transforming your data",
    "section": "Keeping or removing data",
    "text": "Keeping or removing data\nThe next two functions we will look at are filter() (for rows) and select() (for columns). In both cases, we will specify which rows or columns we want to keep, and the rest will be discarded. As with the above two functions, we can use the r in filter to remind us of “rows” and the c in select to remind us of “columns”.\n\nfilter()\nfilter() can be used to keep any rows that meet a certain criteria in a given column. We can keep rows with values which are greater than, less than, or equal to a value, and we can use terms like “and” or “or” (e.g., keep any row if the value is greater than 1 or less than -1).\nWe will pipe the data to the filter function, specify a column name to work from, and then set the threshold for inclusion.\n\n\n\n\n\n\n\n\nNote that we have not changed the order of the rows, or anything else about the data, but only rows collected after the year 2000 are included. If we wanted to include the year 2000, we could use:\n\n\n\n\n\n\n\n\n\nAnd / Or\nWe can also combine operators in either the “and” setting or the “or” setting.\nModify the code below to filter for player information from the year (“yearID” column) 2000 until now and for those who played for the BOS (Boston) team (using the “teamID” column).\nNote 1: when we want to specify equals (as in, teamID is equal to BOS), we must use “==” over “=”.\nNote 2: when using == we must put “BOS” in quotation marks.\nNote 3: here we are using “&”, but in some cases “,” can be used to mean and.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint 1\n\n\n\n\n\nThere are four replacements to make:\n\nSpecify the column: year\nThe operator “greater than or equal to”: &gt;=\nThe year: 2000\nThe teamID: BOS\n\nNote that because BOS is a character, it needs to be in “” marks.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nbbPitching |&gt; filter(yearID &gt;= 2000 & teamID == “BOS”)\n\n\n\n\nWe can also use “or” with two operators, with the | symbol.\n\n\n\n\n\n\n\n\nThis will return all rows where the teamID is “BOS” or is “SFN”.\n\n\n\nselect()\nThe select() function works similarly to filter(), except it defines which columns are kept.\n\nExercise\nHaving worked with arrange(), relocate(), and filter(), see if you work out how select() works. Keep the playerID and teamID, and pipe this to the head() function for display:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nBecause we are keeping two columns we will need to use some form of “and”. You might want to try “&”, but for select() we need to use “,” to separate the columns we want.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nbbPitching |&gt; select(playerID, teamID) |&gt; head()\n\n\n\n\nThe select() function has some alternative syntax that can be useful in certain situations (this is an excellent time to remind you that you don’t need to memorise everything).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nselect() advanced usage\nWe can also use select() to introduce you to a powerful feature of programming languages: the ability to perform pattern matching. We will cover pattern matching another time, but for now we can think of it as not needing to specify the exact name of every single column we want to keep.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise\nWhat if you wanted to select all columns that contained either “R” or “r”?\n\n\n\n\n\n\n\n\n::: { .hint exercise=“ex2_5} ::: { .callout-note collapse=”false”}\nWe need to use the “or” key: |\nYou might try\nbbPitching |&gt; select(contains(“R” | “r”)) |&gt; head()\nBut this will fail. Instead of providing the “|” to the contains() function, instead try providing it to the select() function.\n::: :::\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nbbPitching |&gt; select(contains(“R”) | contains(“r”)) |&gt; head()\nIn this format, the select() function will return any column that “contains R” or “contains r”.\n\n\n\n\nConclude with the ‘things they have in common’ information",
    "crumbs": [
      "Episode 2 - Data Transformations"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Into the tidyverse",
    "section": "",
    "text": "Maybe this is your first encounter with R, or maybe you’ve self-taught and stumbled your way through a plot, or maybe you’ve been using base R for ages and you want to pick up some of the tidyverse (that’s where I fit in, by the way). Whatever your situation, this workshop is going to introduce you to the tidyverse, get you started with some exercises, and then set you loose with enough tools to explore things comfortably (and safely) on your own.",
    "crumbs": [
      "Into the tidyverse"
    ]
  }
]